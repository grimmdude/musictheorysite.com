Wed Mar 21 11:30:02 EDT 2007

Insert date with :r!date

---------------------

procstat configuration in: ~/scripts

Regular expressions in google3: RE::FullMatch (util/regexp/regexp.h)

I0321 175827 stubbybalancer_regtest.cc:822] Total number of requests = 19800 in 102.432 seconds
F0321 175827 stubbybalancer_regtest.cc:834] Check failed: qps > min_num_requests / 60 (193.298 vs. 200)



Instructions on how to change task sizes / properties inside an allocation.

Update job sizes:

$ borg --borguser=igoogle --borg=fg changejobsize --size=59 igoogle.{igfe_filesyncer_server,igfe,logsaver,gdp_slave,igfe.pkgpreloader}/igoogle

Update stupid GDP slave:

$ borgcfg --borguser=igoogle igoogle.borg update fg:igoogle.gdp_slave

Update ig_alloc:

$ borgcfg --borguser=igoogle igoogle.borg updateallocs fg:igoogle.ig_alloc

-------

2006:
Apr 10 - Toronto - California
May 4 - May 9 - California - Toronto - California
May 25 - May 31 - California - Toronto - California
Jun 21 - Jun 28 - California - Tornto - California
Jul - California -> New York
Aug 11 - Aug 14 - NY - Toronto - NY
Oct 13 - Oct 19 - NY - Toronto - NY
Nov 6 - Nov 17 - NY - California - NY
Dec 21 - Jan 7 - NY - Toronto - NY

2007:
Feb 12 - Feb 23 - NY - California - NY
Apr 4 - Apr 12 - NY - Toronto - NY

-----------

iGoogle traffic optimization

TRAFFIC OVER 2s:

analog-mon:2220> select regexp(SourceMachine, '^([a-z][a-z])') AS Colo, count(*) as c from igoogle.igfe_weblog.20070601 where ElapsedTime > 2000 and not (Request contains 'gmail' or Request contains 'feedjson') group by Colo;
+------+---------------+
| colo | count(*) as c |
+------+---------------+
| qb   |         48328 |
| he   |         51613 |
| cg   |             9 |
| ug   |         30217 |
| hs   |         88770 |
| pr   |         69938 |
| nz   |         55434 |
| fg   |         15066 |
+------+---------------+
8 rows in result set (10.05 sec)
Scan rate: 25.08M rows/sec


TOTAL TRAFFIC:

analog-mon:2220> select regexp(SourceMachine, '^([a-z][a-z])') AS Colo, count(*) as c from igoogle.igfe_weblog.20070601 where not (Request contains 'gmail' or Request contains 'feedjson') group by Colo;
+------+---------------+
| colo | count(*) as c |
+------+---------------+
| qb   |      14986376 |
| he   |      52753690 |
| cg   |          4046 |
| ug   |      13525825 |
| hs   |      50030005 |
| pr   |      41529567 |
| nz   |      29987606 |
| fg   |       3929698 |
+------+---------------+
8 rows in result set (20.51 sec)
Scan rate: 12.29M rows/sec


TRAFFIC OVER 1s:

analog-mon:2220> select regexp(SourceMachine, '^([a-z][a-z])') AS Colo, count(*) as c from igoogle.igfe_weblog.20070601 where ElapsedTime > 1000 and not (Request contains 'gmail' or Request contains 'feedjson') group by Colo;
+------+---------------+
| colo | count(*) as c |
+------+---------------+
| qb   |         92820 |
| he   |        135995 |
| cg   |            21 |
| ug   |         65901 |
| hs   |        215693 |
| pr   |        169725 |
| nz   |        119933 |
| fg   |         67723 |
+------+---------------+
8 rows in result set (4.16 sec)
Scan rate: 60.63M rows/sec


TRAFFIC OVER 500ms (SLA):


analog-mon:2220> select regexp(SourceMachine, '^([a-z][a-z])') AS
   colo, count(*) as c from igoogle.igfe_weblog.20070601 where
   ElapsedTime > 500 and not (Request contains 'gmail' or Request
   contains 'feedjson') group by colo;
+------+---------------+
| colo | count(*) as c |
+------+---------------+
| qb   |        193611 |
| he   |        404324 |
| cg   |            49 |
| ug   |        195149 |
| hs   |        726193 |
| pr   |        453324 |
| nz   |        346545 |
| fg   |        182362 |
+------+---------------+
8 rows in result set (4.84 sec)
Scan rate: 52.04M rows/sec


AVERAGE LATENCY:

analog-mon:2220> select sum(ElapsedTime) as s, count(*) as c from igoogle.igfe_weblog.20070601 where not (Request contains 'gmail' or Request contains 'feedjson');
+-----------------------+---------------+
| sum(ElapsedTime) as s | count(*) as c |
+-----------------------+---------------+
|           10422441271 |     206746813 |
+-----------------------+---------------+

>>> 10422441271/206746813.
50.411617571101324

This turns out to be because of the large number of static requests.

Let's strip those out:


analog-mon:2220> select sum(ElapsedTime) as s, count(*) as c from igoogle.igfe_weblog.20070601 where not (Request contains 'gmail' or Request contains 'feedjson' or Request contains '.js');
+-----------------------+---------------+
| sum(ElapsedTime) as s | count(*) as c |
+-----------------------+---------------+
|           10300931042 |     157155186 |
S+-----------------------+---------------+
1 row in result set (4.72 sec)
Scan rate: 53.35M rows/sec

>>> 10300931042/157155186.0
65.546236838789397



analog-mon:2220> select top(Request, 10), count(*) as c from igoogle.igfe_weblog.20070601 where ElapsedTime > 1000 and (Request contains '.js' or Request contains '.png');
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+
| top(Request, 10)                                                                                                                                                                 | count(*) as c |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+
| GET /ig/modules/recommendations/recommend.js HTTP/1.1                                                                                                                            |            27 |
| GET /ig/f/OUxLx6ZYCAw/ig.js HTTP/1.1                                                                                                                                             |            26 |
| GET /ig/ifr?url=http://www.jacobparr.com/googlegadgets/bills.jsp&nocache=2147483647&lang=en&country=us&.lang=en&.country=us&synd=ig&mid=78&parent=http://www.google.com HTTP/1.1 |            21 |
| GET /ig/modules/chinese_module_content/calendar.js HTTP/1.1                                                                                                                      |            19 |
| GET /ig/ig_popup.js HTTP/1.1                                                                                                                                                     |            16 |
| GET /ig/f/nBWa-gOQ-hg/lib/libgrid.js HTTP/1.1                                                                                                                                    |            14 |
| POST /ig/proxy?et=6ptHuzzZ&hdrs=Content-Length%253A46&url=http%3A%2F%2Ftwitter.isite.net.au%2Fstatuses%2Ffriends_timeline.json HTTP/1.1                                          |            11 |
| GET /ig/modules/chinese_module_content/weather.js HTTP/1.1                                                                                                                       |            11 |
| POST /ig/proxy?et=B861p03H&hdrs=Content-Length%253A46&url=http%3A%2F%2Ftwitter.isite.net.au%2Fstatuses%2Ffriends_timeline.json HTTP/1.1                                          |            10 |
| POST /ig/proxy?et=-Fgcsn7I&hdrs=Content-Length%253A46&url=http%3A%2F%2Ftwitter.isite.net.au%2Fstatuses%2Ffriends_timeline.json HTTP/1.1                                          |            10 |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+
WARNING: TOP() results may be approximate
10 rows in result set (4.21 sec)
Scan rate: 60.80M rows/sec

--------------------------------------------

Out of 425,666,514 total requests:

6913 > 1000
26910 > 500
425100 > 100

------------

Security:

555 Prospect Associates


Fee:

McKinley Jones

-----------------

 select format_time_usec(eventid.time_usec + (elapsedtime * 1000)) as a, elapsedtime from igoogle.igfe_weblog.20070620 where SourceMachine = "hek58" and eventid.time_usec >1182368104000000 and eventid.time_usec < 1182368144000000 order by a;


--------------------
Tablet of death

 bt --gfs_user=blogsearch-prod quarantine /bigtable/blogsearch-prod-nz-srv-01/Output "http://www.airsoftradio.com/2006/07/click-here-for-airsoft-radio-for.htm|P|eca08c3f59cbb004"

bt --gfs_user=blogsearch-prod quarantine /bigtable/blogsearch-prod-nz-srv-01/Output "http://www.megsastm.com/180/|P|fe07a0ff876b527b"

 bt --gfs_user=blogsearch-prod quarantine /bigtable/blogsearch-prod-nz-srv-01/Output 'http://www.cybaea.net/Journal/connecting_people_creative_enterprise.html|P|28d942b6813cd69b'

 bt findrow /bigtable/blogsearch-prod-nz-srv-01/Output
   'http://www.cybaea.net/Journal/connecting_people_creative_enterprise.html|P|28d942b6813cd69b'


  188 http://www.aish.com/|B|ae1582ea6ef1d8d0
    191 http://www.ajaydsouza.org/index.php|B|3c1606b34e3db3b5
    221 http://www.airtonjo.com/blog/|B|6b7ec6501a7e21a2
    295 http://www.airtravelcenter.info/|B|6a59212c9031a0cd
    300 http://www.aivy.co.jp/BLOG_TEST/nagasawa/|B|dd52e123407f9527
    310 http://www.ajax-blog.com/|B|6a5aede9a8b32155
    328 http://www.aizu-tv.com/tarouclub/|B|2e5ca89cc38448c1
    510 http://www.airwarriors.com/forum/|B|5a6d17dc945d1d8f
    558 http://www.airstreamforums.com/forums/|B|422ebd45bb525549
   1579 http://www.airteamimages.com/|B|6cca65f455eba369


---

Pay rent to 555 Prospect Associates (Note: 565/10B)

My address: 565 Prospect Pl., Apt 10B, NY 11238

Call Con Edison for Power / Keyspan for Gas (Done)

- Keyspan coming in on Jul 5th

----------------------------------------


550 - solie

----------------

CORP LOASD

/home/build/static/projects/loas/corp-loasd

----------------------

Stubby Balancers with LOAS

Server:

bin/balancing/stubby/stubbybalancer_deleg_test_server
   --loas_proxy_roles_trusted_for_delegation mmuthanna --logtostderr

Client:

bin/balancing/stubby/stubbybalancer_deleg_test_client --username
   mmuthanna --server_spec localhost:5000 --default_username mmuthanna
   --proxy_username mmuthanna

Proxy:

bin/balancing/stubby/stubbybalancer --default_deadline=4
   --lb_client_withdrawn_backend_delete_timeout_in_secs=60
   --lb_list=ikbladelb1.prodz.google.com:9480,ikbladelb2.prodz.google.com:9480
   --lbhttprequest_dns_check_timeout_in_ms=30000 --max_requests=2000
   --rtsignals --startup_blackout_period_in_ms=5000
   --stubby_services=massage:5000#mmuthanna2:9001
   --enable_loas_simple_delegation --default_delegated_role mmuthanna
   --logtostderr


Notes:

Not setting --default_delegated_role, will enfore LOAS on all incoming
RPC calls.




-----------

Called about car:

sayed - 647 835 0148



-------------------------

Create a new crash chubby cell
------------------------------

http://b/issue?id=838543


$ mdb ri -s free -d au -o chubby-co
-----------------------------------------------------------------------
machine  state  owner      health  [service,servertype,port,stage]...  
-----------------------------------------------------------------------
aua9     free   chubby-co  good                                        
aub4     free   chubby-co  good                                        
auc9     free   chubby-co  good                                        
aum1     free   chubby-co  good                                        
auaa7    free   chubby-co  good                                        
auff4    free   chubby-co  bad       


$ mdb ri -N -s free -d au -o chubby-co
aua9 aub4 auc9 aum1 auaa7 auff4 

$ mdb ri -s serving -d au -o chubby-co


# Machine auff4 is bad... find out why:

$ mdb lsprb -m auff4
------------------------------------------------------------------------------------------------------------
machine_name  problem_id  case_id  iteration  symptom        severity  priority  reporter  solver   notes   
------------------------------------------------------------------------------------------------------------
auff4         41528443    NULL     NULL       manual-repair  3         medium    bjk       repairs  NULL    
auff4         41528514    NULL     NULL       memory-errors  3         medium    bjk       repairs  NULL    
auff4         41528732    NULL     NULL       draining       3         medium    bjk       repairs  enrep!  


# chubby-co is a member of chubby

# First find a GFS cell close to the target cluster. Do not use the same
   cell (circular dependency).

# Make sure that the GFS cell is not already being used by another
   crash cell by checking "google/config/config.chubby.crash" 


# Create the GFS backup directory

$ fileutil -gfs_user=chubby mkdir -p -g chubby /gfs/bf/chubby/au-crash

$ fileutil -gfs_user=chubby ls -l -d /gfs/bf/chubby/au-crash
drwxrwxrwx 1 chubby    chubby               0 1969/12/31 19:00:00 /gfs/bf/chubby/au-crash

# Create a servers file in google/config. 


# cp servers.chubby.crash.bx servers.chubby.crash.au

# g4 add servers.chubby.crash.au


# Add the servers from the "mdb -N" commandline.

# Empty out the REPLACEMENTS. (filled in by autoreplacer)

# We can use the same machines for svelte or stout

# Take out svelte and stout

We end up with:

# -*- Python -*-

COLOC = 'au'
CELL = 'au-crash'
INCLUDES = ['config.chubby.crash']

SERVERS = {

  # CHUBBY
  6200 : " aua9 aub4 auc9 aum1 auaa7 ",

}

REPLACEMENTS = {
}


# $ g4 edit config.chubby.crash

Edit LOCKSERVER_BACKUP_GFS_CELL


# Edit services.au, and add chubby_crash instances to it. Add it to:
   BABYSIT, NO_BINCHECK, and SERVICES (Misc).

# Run babysitter regression tests

$ g4 pending
Change default : 
  //depot/google/config/...
    config.chubby.crash #25 - edit (text)
    servers.chubby.crash.au #1 - add (text)
    services.au #65 - edit (text)

$ g4 client -o


        //depot/google3/__init__.py //mmuthanna-babysitter/google3/__init__.py
        //depot/google/__init__.py //mmuthanna-babysitter/google/__init__.py
        //depot/google/config/... //mmuthanna-babysitter/google/config/...
        //depot/google/gfe/... //mmuthanna-babysitter/google/gfe/...
        //depot/google/production/... //mmuthanna-babysitter/google/production/...
        //depot/google/setup/... //mmuthanna-babysitter/google/setup/...
        //depot/googledata/regression/restarter_unittest/orig/... //mmuthanna-babysitter/googledata/regression/restarter_unittest/orig/...
        //depot/googledata/regression/googleconfig_unittest/... //mmuthanna-babysitter/googledata/regression/googleconfig_unittest/...


# make sure your machine is in: /home/build/google/production/babysitter/workers.nyc

$ g4 nothave

# from google/config:

$ ../production/babysitter/babysitter_test.sh --use_multidiff

Select option 1.

# Sync MDB with servers file. (Make sure ssh-agent is running)

$ syncdb servers.chubby.crash.au

$ mdb ri -s serving -d au -o chubby-dev
-----------------------------------------------------------------------------------------------------------------------------------------------------------
machine  state    owner       health  [service,servertype,port,stage]...                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------
aua9     serving  chubby-dev  good    chubby_crash chubby 6200 pending, chubby_crash chubbydnsserver 6287 pending, chubby_crash chubbymirror 6209 pending  
aub4     serving  chubby-dev  good    chubby_crash chubby 6200 pending, chubby_crash chubbydnsserver 6287 pending, chubby_crash chubbymirror 6209 pending  
auc9     serving  chubby-dev  good    chubby_crash chubby 6200 pending, chubby_crash chubbydnsserver 6287 pending, chubby_crash chubbymirror 6209 pending  
aum1     serving  chubby-dev  good    chubby_crash chubby 6200 pending, chubby_crash chubbydnsserver 6287 pending, chubby_crash chubbymirror 6209 pending  
auaa7    serving  chubby-dev  good    chubby_crash chubby 6200 pending, chubby_crash chubbydnsserver 6287 pending, chubby_crash chubbymirror 6209 pending


$ g4 submit

# Wait for change to propogate to the aubaby machine (babysitter at au).

# Setup machines (kernel, installs binaries)

 $ ssh produser@aumcp.prodz.google.com '(source /etc/profile; cd /root/google/config; ../production/assigner/setup_mach.py --force servers.chubby.crash.au)'


# find out about production DNS



-------------------------------
5/Sep/07

- Drain QB
- Push to FP
- Update the Logsavers
- Chubby AU push
- GDP update by Jeremy

------------

Ping Queue

qq.com - not spam
webd.pl - hosting (.glt.pl / webd.pl) (141K sites)
xorg.pl - 86K sites
wwwundzwei.eu - 659 sites
12e.jp -  4672 sites
blogtt.com
webf.pl
fc2.com
persianblog.ir
yube.pl
chb.net
seesaa.net
sblo.jp
goo.ne.jp

---------------------------

Clean up GFS alerts:

fileutil ls /gfs/nz/home/mmuthanna/alerts/archive/alerts.db.* | sort
   -n -k 49,58 | head -1980 | xargs fileutil --force rm

---------------------------

Dremel: Sort Search History Queries by response code

   select count(*) as cnt, ResponseCode from
   kansas_smh.smhweblog.20070923 group by ResponseCode order by cnt
   desc limit 20;


----------------------

Setup stout in UG and WF

------------------


Building Asterisk with GTALK
----------------------------

Get debian package iksemel.

$ patch -p0 <../gtalk...
(correct path for 1.4.9)

CFLAGS=-g ./configure --prefix= --exec_prefix=

$ make menuconfig

Compile in everything (don't need cdr or apps)

------------------------

RPC Analyzer
-------------


/home/build/static/projects/gfs/rpc-analyzer --mode=trace
   -starttime=2007/10/12-00:21:00 --duration=300
   lockserver.gvfs35.prodsetup.log.BINARY_INFO.20071011-202815.2074 >
   rpclog.2121



 $ /home/build/static/projects/chubby/dissector
   -starttime=2007/10/11-21:21:00 -duration=300
   lockserver.gvfs35.prodsetup.log.BINARY_INFO.20071011-202815.2074 

2007/10/11-21:21:00.060 - 2007/10/11-21:25:59.579 (GoogleTime): 96757
   records (323.042 per second)

Per method:
  KeepAlive            78.1%,    253.2/s, 75603 total
  Open                  6.3%,     20.4/s, 6119 total
  GetStat               5.9%,     18.9/s, 5662 total
  MiniStat              3.3%,     10.9/s, 3202 total
  Null                  1.7%,      5.5/s, 1637 total
  ReadDir               1.5%,      4.9/s, 1476 total
  GetContents           1.0%,      3.7/s, 958 total
  NewSession            1.0%,      3.1/s, 920 total
  EndSession            0.8%,      2.5/s, 741 total
  Close                 0.3%,      1.0/s, 284 total
  SetContents           0.1%,      0.4/s, 101 total
  ReleaseExclusive      0.0%,      1.0/s, 29 total
  Delete                0.0%,      0.1/s, 16 total
  AcquireExclusive      0.0%,      0.4/s, 8 total
  TryAcquireExclusive   0.0%,      1.0/s, 1 total

Per status:
  0:000  94.8%,    306.3/s, 91754 total
  6:207   2.9%,      9.5/s, 2847 total
  6:201   1.1%,      3.5/s, 1019 total
  4:009   0.6%,      2.3/s, 615 total
  6:302   0.3%,      1.1/s, 296 total
  4:001   0.1%,      0.4/s, 112 total
  1:000   0.0%,      0.1/s, 37 total
  4:004   0.0%,      0.1/s, 33 total
  4:003   0.0%,      0.2/s, 30 total
  4:007   0.0%,      0.0/s, 8 total
  3:000   0.0%,      0.1/s, 6 total

Top 5 users:
  bt-sre-dedicated  37.2%,    120.5/s, 35952 total
  smartass          16.1%,     53.4/s, 15615 total
  images-prod        9.9%,     32.7/s, 9550 total
  prodbin            7.7%,     24.9/s, 7447 total
  falcon             5.0%,     16.7/s, 4862 total

Top 5 binaries:
  svelte_server           54.3%,     20.8/s, 6145 total
  milldump                17.3%,      6.9/s, 1959 total
  file_loader              8.1%,      3.1/s, 920 total
  mixserver                6.7%,      2.6/s, 757 total
  bigtable_tablet_server   4.1%,      1.6/s, 463 total

Top 5 IPs:
  10.16.194.25   6.3%,     20.8/s, 6138 total
  10.16.245.31   0.8%,     10.9/s, 732 total
  10.16.75.34    0.7%,      2.1/s, 634 total
  10.16.163.4    0.6%,      8.5/s, 594 total
  10.16.81.25    0.6%,      8.9/s, 594 total

Top 5 paths:
  /bigtable/images-prod-thumbnails-gv/tables/thumbnails  17.4%,
   54.4/s, 3096 total
  /bigtable/srv-gv/tables/bt-sre.slowpoke                 4.3%,
   15.1/s, 774 total
  /slave/logs/metacluster.cfg                             4.0%,
   2.5/s, 707 total
  /quality/eval                                           3.3%,
   2.0/s, 596 total
  /bigtable/images-prod-thumbnails-gv/tables/METADATA     2.9%,
   9.9/s, 515 total

Paxos Rejects: 0/s, 0 total.



$ /home/build/static/projects/chubby/dissector
   -starttime=2007/10/11-21:00:00 -duration=300
   lockserver.gvfs35.prodsetup.log.BINARY_INFO.20071011-202815.2074 

2007/10/11-21:00:00.007 - 2007/10/11-21:04:59.949 (GoogleTime): 94217
   records (314.118 per second)

Per method:
  KeepAlive         92.9%,    292.0/s, 87536 total
  Open               1.7%,      5.3/s, 1597 total
  Null               1.4%,      4.4/s, 1307 total
  NewSession         1.2%,      3.9/s, 1170 total
  EndSession         1.0%,      3.4/s, 973 total
  ReadDir            0.7%,      2.2/s, 664 total
  Close              0.3%,      1.1/s, 321 total
  MiniStat           0.2%,      0.8/s, 229 total
  GetContents        0.2%,      0.6/s, 169 total
  GetStat            0.1%,      0.4/s, 124 total
  SetContents        0.1%,      0.3/s, 88 total
  Delete             0.0%,      0.1/s, 21 total
  AcquireExclusive   0.0%,      0.0/s, 9 total
  ReleaseExclusive   0.0%,      0.0/s, 9 total

Per status:
  0:000  98.1%,    308.2/s, 92450 total
  6:207   1.0%,      3.4/s, 972 total
  4:009   0.3%,      1.0/s, 299 total
  6:201   0.1%,      0.5/s, 130 total
  4:001   0.1%,      0.4/s, 118 total
  4:007   0.1%,      0.4/s, 82 total
  4:004   0.1%,      0.3/s, 75 total
  1:000   0.1%,      0.2/s, 52 total
  4:003   0.0%,      0.1/s, 37 total
  3:000   0.0%,     39.4/s, 2 total

Top 5 users:
  bt-sre-dedicated  41.5%,    130.3/s, 39071 total
  smartass          19.3%,     62.3/s, 18195 total
  falcon             6.3%,     20.2/s, 5904 total
  prog:rpcbalancer   5.6%,     17.9/s, 5231 total
  images-prod        5.2%,     16.9/s, 4916 total

Top 5 binaries:
  milldump       49.0%,      9.1/s, 2549 total
  file_loader    24.0%,      4.2/s, 1249 total
  saw             8.1%,      1.5/s, 421 total
  mixserver       6.4%,      1.2/s, 335 total
  svelte_server   2.2%,      0.4/s, 115 total

Top 5 IPs:
  10.16.75.34    0.7%,      2.2/s, 644 total
  10.16.193.34   0.4%,      1.4/s, 391 total
  10.16.233.15   0.4%,      1.3/s, 374 total
  10.16.159.35   0.4%,      1.4/s, 365 total
  10.16.202.25   0.4%,      1.3/s, 363 total

Top 5 paths:
  /slave/logs/metacluster.cfg                                29.3%,
   3.2/s, 933 total
  /quality/eval                                              18.6%,
   2.0/s, 592 total
  /slave/namespace/g.namespace                               10.2%,
   1.1/s, 324 total
  /borg/gv/bns/wwwglobal-prod/wwwglobal.link/meta             1.8%,
   0.2/s, 56 total
  /borg/gv-mgt/bns/mustang/mustang.cluster.cacheserver/meta   1.8%,
   0.2/s, 56 total

Paxos Rejects: 0/s, 0 total.


 $ /home/build/static/projects/gfs/rpc-analyzer --mode=count
   -starttime=2007/10/12-00:21:00 --duration=300
   lockserver.gvfs35.prodsetup.log.BINARY_INFO.20071011-202815.2074 
     5 :     0.00 MB ->     0.00 MB; /GFS_MasterInterface.Match
    93 :     0.04 MB ->     0.03 MB; /LocAS.ServerGetNewSessionKey
     8 :     0.00 MB ->     0.00 MB; /LockServerWire.AcquireExclusive
   284 :     0.04 MB ->     0.13 MB; /LockServerWire.Close
    16 :     0.00 MB ->     0.01 MB; /LockServerWire.Delete
   741 :     0.07 MB ->     0.07 MB; /LockServerWire.EndSession
   958 :     0.16 MB ->     0.94 MB; /LockServerWire.GetContents
  5662 :     0.91 MB ->     2.38 MB; /LockServerWire.GetStat
 75607 :     7.85 MB ->     9.08 MB; /LockServerWire.KeepAlive
  3202 :     0.50 MB ->     1.71 MB; /LockServerWire.MiniStat
   920 :     0.08 MB ->     0.31 MB; /LockServerWire.NewSession
  1649 :     0.13 MB ->     0.12 MB; /LockServerWire.Null
  6119 :     1.12 MB ->     4.51 MB; /LockServerWire.Open
  1476 :     0.22 MB ->     1.26 MB; /LockServerWire.ReadDir
    29 :     0.01 MB ->     0.00 MB; /LockServerWire.ReleaseExclusive
   101 :     0.29 MB ->     0.05 MB; /LockServerWire.SetContents
     1 :     0.00 MB ->     0.00 MB;
   /LockServerWire.TryAcquireExclusive
  2832 :     1.68 MB ->     0.12 MB; /PaxosService.Accept
  2832 :     0.39 MB ->     0.12 MB; /PaxosService.AcceptAck
  2832 :     0.37 MB ->     0.12 MB; /PaxosService.Commit


> pts/21 mmuthanna@mmuthanna2:/opt/work/chubby
> 0 11:34:14 $ /home/build/static/projects/gfs/rpc-analyzer
   --mode=count -starttime=2007/10/12-00:00:00 --duration=300
   lockserver.gvfs35.prodsetup.log.BINARY_INFO.20071011-202815.2074 
     5 :     0.00 MB ->     0.00 MB; /GFS_MasterInterface.Match
    69 :     0.03 MB ->     0.02 MB; /LocAS.ServerGetNewSessionKey
     9 :     0.00 MB ->     0.00 MB; /LockServerWire.AcquireExclusive
   321 :     0.05 MB ->     0.16 MB; /LockServerWire.Close
    21 :     0.00 MB ->     0.01 MB; /LockServerWire.Delete
   973 :     0.09 MB ->     0.09 MB; /LockServerWire.EndSession
   169 :     0.03 MB ->     1.88 MB; /LockServerWire.GetContents
   124 :     0.02 MB ->     0.06 MB; /LockServerWire.GetStat
 87539 :     9.09 MB ->    10.43 MB; /LockServerWire.KeepAlive
   229 :     0.03 MB ->     0.14 MB; /LockServerWire.MiniStat
  1170 :     0.10 MB ->     0.40 MB; /LockServerWire.NewSession
  1316 :     0.10 MB ->     0.09 MB; /LockServerWire.Null
  1597 :     0.80 MB ->     1.83 MB; /LockServerWire.Open
   664 :     0.09 MB ->     0.51 MB; /LockServerWire.ReadDir
     9 :     0.00 MB ->     0.00 MB; /LockServerWire.ReleaseExclusive
    88 :     0.77 MB ->     0.04 MB; /LockServerWire.SetContents
  1256 :     2.12 MB ->     0.05 MB; /PaxosService.Accept
  1256 :     0.17 MB ->     0.05 MB; /PaxosService.AcceptAck
  1256 :     0.16 MB ->     0.05 MB; /PaxosService.Commit

$ cat fds.from.gv  | grep '620.*' | grep LIST
lockserve 2302 prodsetup   20u  IPv4 163683559                  TCP
   *:6205 (LISTEN)
lockserve 2302 prodsetup  101u  IPv4 163683741                  TCP
   *:6201 (LISTEN)
lockserve 2302 prodsetup  113u  IPv4 163683742                  TCP
   *:6204 (LISTEN)
lockserve 2302 prodsetup  133u  IPv4 163683797                  TCP
   *:6200 (LISTEN)
lockserve 2302 prodsetup  144u  IPv4 163683811                  TCP
   *:6203 (LISTEN)
lockserve 2302 prodsetup  145u  IPv4 163683812                  TCP
   *:6202 (LISTEN)

> pts/21 mmuthanna@mmuthanna2:/opt/work/chubby
> 0 12:02:26 $ cat fds.from.gv  | grep '620.*' | grep UDP 
lockserve 2302 prodsetup   40u  IPv4 163683614                  UDP
   *:6205 
lockserve 2302 prodsetup  124u  IPv4 163683784                  UDP
   *:6201 
lockserve 2302 prodsetup  146u  IPv4 163683813                  UDP
   *:6202 
lockserve 2302 prodsetup  147u  IPv4 163683814                  UDP
   *:6203 
lockserve 2302 prodsetup  160u  IPv4 163683841                  UDP
   *:6200 

------------

SRCFS

Make sure srcfsd is running (need to install with apt-)

Then, you'll need to run:

$ srcfs login (or srcfs sync)

$ mkdir google3; cd google3
$ gcheckout --add production/monitoring (don't use gcheckout without --add)

BLAZE

$ blaze build java/com/google/codelab/flags:all
$ ./blaze-bin/com/.../Fortune

Building for deployment

$ blaze build java/com/google/codelab/flags/Fortune_deploy.jar

---------------------

Restart chubby in a cell (emergency)

cd /home/build/google/config
$ bbs --start=all servers.chubby.local.ht

(There's also global, rib, crash, etc.)

(These files include svelte)

- On prod machines, they're in /root/google/config
  *  syncbaby.py syncs these files
  * Logs are in /export/hda3/tmp
  * SSH logs are in /var/log/sshlog

-----------

Chubby troubleshooting:

Master configuration file (chubby, svelte, etc.):

- //depot/google/config/config.chubby.prod
  * Associated flags are stored in ///google/config/servertype_restarts.py

Per datacenter files:

- //depot/google/config/services.DC
  * Has a list of all services per datacenter

- //depot/google/config/servers.chubby.local.hs
  * Has the hostnames of servers, and replacement information

Production Integrate Branch

- /home/build/production_release/google/config

Check autoreplacer:

$ mdb autorepl -m machine

http://autorepl

MDB replacement machine histories:

$ mdb lssrvrqh -i 3005391

Babysitter restart a single server:

bbs --start="chubby" --mach="tijj2" servers.chubby.local.ti

Cancel autoreplacer:

First get repl_id for machine (-o specifies hostname of original machine):

$ mdb lssrvrq -o cgb36
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
machine_name  repl_id  batch_id  datacenter  service  serverset  port  old_machid  new_machid  priority  start_time           urgent  op       state      state_time           failure_type  num_failures  comments  reviewers  
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
cgb36         5392612  3487704   cg          chubby   svelte     6297  2258671     2530780     NULL      2009-06-03 03:59:48  no      replace  completed  2009-06-03 09:31:16  data_push     1             NULL      NULL       

Then cancel request (sometimes there are multiple requests to remove):

$ mdb rmsrvrq -i 5392612

--------------

Bladeservice copy GFS packages

$ for dc in /home/build/google3/production/borg/bladeservice/??; do \
   fileutil mkdir -p /gfs/`basename $dc`/home/bladeservice/versions/27; done


Check machine

$ cm hscv47

-------------------

Chubby list machines

$ chubby_lsmast ls-rib

List master

$ chubby_lsmast -m ls-rib

-----------

$ aptitude search make

--------------


Setting up Asterisk on goobuntu:
-------------------------------

Directories:

/opt/dev: Build dirs. All sources extracted here.
/opt/phone: Application dirs.

* Build asterisk

$ apt-get flex bison gcc cpp g\+\+ make build-essential
   libncurses5-dev zlib1g-dev libssl-dev libnewt-dev

$ ./configure --prefix=/opt/asterisk
   --exec_prefix=/opt/asterisk

$ make menuconfig (Use defaults)

$ make; make install; make samples

* Install Asterisk (alternate)

$ apt-get -t extras install asterisk

Edit /etc/default/asterisk first and set RUNASTERISK to yes.

* Install Festival Lite

$ apt-get install flite flite-dev

* Build and install app_flite

$ svn co https://dialogpalette.svn.sourceforge.net/svnroot/dialogpalette dialogpalette

$ cd trunk/asterisk-flite

(Edit Makefile and add)

ASTERISKINCLUDE=-I/opt/dev/asterisk-1.4.13/include
ASTERISKMODDIR=/opt/phone/asterisk/lib/asterisk/modules

$ make; make install

Restart asterisk and:

CLI> show application flite

* Have corp-telecom whitelist your server. (kwallace can do this)

* Asterisk sip.conf (for corp-telecom):

[google]
type=friend
host=172.24.8.93 ;The IP address of the local machine
outboundproxy=sj2sip1.corp.google.com

[google_ame]
type=friend
host=172.25.209.81
outboundproxy=pstngw.ame.corp.google.com

* Setup a test extension (in extensions.conf):

[googletest]
exten => s,1,Answer
exten => s,n,Playback(demo-thanks)      ; "Thanks for trying the demo"
exten => 1,1,Hangup

* Enable asterisk manager

Edit /etc/asterisk/manager.conf. 

enabled = yes

[phone]
secret = ph0ne
write = call


* Now test a call. Create this script:

#!/bin/sh

SPOOL=/var/spool/asterisk/outgoing
TEMP=`/bin/mktemp /tmp/$0.XXXXXX`
SOURCE=172.25.189.35
TARGET=$1
MESSAGE=$2

cat >$TEMP <<GROK
Channel: SIP/$TARGET@google
MaxRetries: 0
RetryTime: 30
WaitTime: 60
Context: googletest
Extension: s
Priority: 1
SetVar: SourceNumber=$SOURCE
SetVar: TargetNumber=$TARGET
SetVar: Message=$MESSAGE
GROK

# Callerid: $SOURCE
# Callerid: 12125657243

mv $TEMP $SPOOL

* And run it.

$ ./test.sh 712125656156 (Note the 7 for outside line)

* [DEPRECATED] Good. Now lets' get festival configured (/etc/festival.scm).

$ apt-get install festival

; Audio
(Parameter.set 'Audio_Method 'linux16audio)
;(Parameter.set 'Audio_Method 'esdaudio)
;(Parameter.set 'Audio_Method 'mplayeraudio)
;(Parameter.set 'Audio_Method 'sunaudio)

; For a list of voices, look in /usr/share/festival/voices/
; To use the mbrola voices, you must emerge festival with USE='mbrola'
; us1_mbrola is my (eradicator) personal favorite voice.
;(voice_us1_mbrola)

; Maximum number of clients on the server
(set! server_max_clients 10)

; Server port
(set! server_port 1314)

; Log file location
(set! server_log_file "/var/log/festival.log")

; Set the server password
(set! server_passwd nil)

; Server access list (hosts)
(set! server_access_list '("[^.]+" "127.0.0.1" "localhost.*"
   "192.168.*"))

; Server deny list (hosts)
(set! server_deny_list nil)

;;; Command for Asterisk begin
(define (tts_textasterisk string mode)
    "(tts_textasterisk STRING MODE)
  Apply tts to STRING.  This function is specifically designed for
  use in server mode so a single function call may synthesize the
   string.
  This function name may be added to the server safe functions."
      (utt.send.wave.client (utt.wave.resample (utt.wave.rescale
   (utt.synth
                    (eval (list 'Utterance 'Text string))) 5) 8000)))
;;; Command for Asterisk end 


* [DEPRECATED] Asterisk Festival configuration (festival.conf)
;
; Festival Configuration
;
[general]
;
; Host which runs the festival server (default : localhost);
;
host=localhost
;
; Port on host where the festival server runs (default : 1314)
;
port=1314
;
; Use cache (yes, no - defaults to no)
;
; Some obsure bug causes festival to hang when caching is enabled.
;
usecache=no
;
; If usecache=yes, a directory to store waveform cache files.
; The cache is never cleared (yet), so you must take care of cleaning
   it
; yourself (just delete any or all files from the cache).
; THIS DIRECTORY *MUST* EXIST and must be writable from the asterisk
   process.
; Defaults to /tmp/
;
cachedir=/var/lib/asterisk/festivalcache/
;
; Festival command to send to the server.
; Defaults to: (tts_textasterisk "%s" 'file)(quit)\n
; %s is replaced by the desired text to say. The command MUST end with
   a
; (quit) directive, or the cache handling mechanism will hang. Do not
; forget the \n at the end.
;
festivalcommand=(tts_textasterisk "%s" 'file)(quit)\n

* [DEPRECATED] Edit /etc/init.d/festival.conf and comment out the "exit 0" and start.

$ /etc/init.d/festival start

* Setup the extension context for paging

[page-user]
exten => s,1,Wait(1)
exten => s,2,Flite(${Message})
exten => s,5,Wait(1)
exten => s,6,Hangup

* Create page.sh:

#!/bin/sh

SPOOL=/var/spool/asterisk/outgoing
TEMP=`/bin/mktemp /tmp/pager.XXXXXX`
SOURCE=172.25.189.35
TARGET=$1
MESSAGE=$2

cat >$TEMP <<GROK
Channel: SIP/$TARGET@google
MaxRetries: 0
RetryTime: 30
WaitTime: 60
Context: page-user
Extension: s
Priority: 1
Callerid: 12125656156
SetVar: SourceNumber=$SOURCE
SetVar: TargetNumber=$TARGET
SetVar: Message=$MESSAGE
GROK

# Callerid: $SOURCE

mv $TEMP $SPOOL


* Restart asterisk, and test

$ ./page.sh 712125656156 "yomama sucks for money"

* If that works, copy over page.rb to your work directory.

* Now setup mail server and forward mail to page.rb.

* Add alias as so:

pager:          |/opt/phone/page.rb

* Edit postfix configuration file

# cat /etc/postfix/main.cf 
# See /usr/share/postfix/main.cf.dist for a commented, more complete
   version

smtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)
biff = no

# appending .domain is the MUA's job.
#append_dot_mydomain = no

# Uncomment the next line to generate "delayed mail" warnings
#delay_warning_time = 4h

myhostname = chatterbot.corp.google.com
alias_maps = hash:/etc/aliases
alias_database = hash:/etc/aliases
mydomain = talk.corp.google.com
myorigin = $mydomain
mydestination = $mydomain $myhostname localhost smtp.corp.google.com
relayhost = 
mynetworks = 127.0.0.0/8
mailbox_size_limit = 0
recipient_delimiter = +
inet_interfaces = all
message_size_limit = 20000000
default_privs = asterisk
propagate_unmatched_extensions = canonical, virtual, alias

* Fix permissions

$ chown -r asterisk:asterisk /opt/phone 
$ chmod g+w /opt/phone/log /opt/phone/spool \
            /var/spool/asterisk /var/spool/asterisk/outgoing

* Add to /etc/group 

asterisk:x:110:postfix

$ /etc/init.d/nscd restart

*** Remember that postfix adds an X-Original-To header, and does not
   do Envelope-to.




------------------------------------


Troubleshoot ServerThrottling

$ /home/build/static/projects/chubby/dissector -master=nzi7 -starttime
   07:45:00 -duration 600

--

Perforce p4 history:

g4 shortlog config.chubby.prod

---

LOAS flags:

--rpc_use_default_security=loas --gfs_enable_stubby_client
   --gfs_client_security_level=integrity

For older binaries:

--gfs_cell_args=default=security_level:integrity
   --gfs_enable_stubby_client

More info:
http://wiki.corp.google.com/twiki/bin/view/Main/DrawbridgeFiveColos

Borg package (top level above job):

options {
  fileutil_loas_level = "integrity"
  append_checksum = true  // not strictly required, see note below
}

Need this for fileutil and borgcfg:
  
$ export GFS_CLIENT_SECURITY_LEVEL=integrity

For java apps:

--jvm_flags="-DFLAGS_gfs_enable_stubby_client=true
   -DFLAGS_gfs_cell_args=default=security_level:integrity -DFLAGS_lockservice_use_loas=true"

----------------

Getting symbol information for chubby:

List the releases:
p4 -p release-archive:1666 files //releases/chubby/...

Fetch the binary: (notice '-q'):
p4 -p release-archive:1666 print -q
//releases/chubby/200709/20070910-2259/lockserver#1 > t

Sync CL to:

wiki/Main/ChubbyRollout

$ g4 sync @5430291

$ gcheckout chubby/BUILD @5430291


--------------

GDB in Google (gdb)

$ /home/build/static/projects/tools/gdb
(gdb) set solib-absolute-prefix /home/build/sysimages/base/prod71/tree
(gdb) file _binary-file_
(gdb) core-file core


---------

Get chubby backup cell:

$ chubby_get_backup_cell nz

--------------------------

start-stop-daemon --start --exec
   /home/mmuthanna/work/telebot/telebot/telebot/bin/telebot
   --background --make-pidfile --pidfile /tmp/telebot.pid -v

start-stop-daemon --stop --retry 30 --pidfile /tmp/telebot.pid -v


---------

Asterisk Ruby

$ gem install -r AsteriskRuby

----------

panic room tickets

684142
691133
691121
707338
744824
759840
792103

----------------------------

Need bladeservice resources in:

KC


--------------------

Babysitter FAQ

https://www.corp.google.com/eng/production/docs/external/babysitter-faq.html

$ list_config 


------------------

Falcon troubleshooting
 
    * GFS quota exceeds, this is something that James is trying to
   fix, just remove the files
   /namespace/g/falcon/xx/production/data/*/*ping_milldump* that are 4
   hours old.
    * PingDataAnalyzer_Livehost_Read_Errors: this is not documented
   yet, James is looking at this, and will update the status when he
   is done.

--------------

Droste chocolate / or recchiuti

full cream milk - heated slowly
2 parts coco, 1pt granulated sugar


2 tblspoons per 8 ounces of milk.
After slow boil (milk), add coco.
whisk for 3 minutes.

add sugar last...

keep whisking.

-----------------------

Svelte troubleshooting rpc-analyzer:

rpc-analyzer --mode=dump --type=ModifyWaitset \
   svelte_server.fpx23.prodbin.log.BINARY_INFO.20071205-133512.2828 | \
   awk '{if ($3 == 2 && $4 > 100000) {print}}'

-------------

Building Flint (flint)
<>
$ srcfs login
$ g4 client
$ mkdir google3; cd google3
$ gcheckout --add third_party/flint
$ srcfs sync
$ gconfig third_party/flint/glint
$ make-dbg -r third_party/flint/glint




------------

lockserv resolve without svelte:

$ lockserv resolve /bns/ep/borg/ep/bns/falcon/falcon.falcon_borgmon/0
   --logtostderr --bnsresolver_use_svelte=false

------------

Falcon SRE issues:

 * Need proper global monitoring dashboard
 * Falcon per-datacenter configuration too generic. Different
   datacenters behave differently, and need to be tuned correctly.
 * Many jobs running at very low priorities, and get pre-empted, and
   these cause alerts to fire.
 * Many alerts fire for days without response. Are these alerts then
   critical?
 * Many alerts are spammy, and fire too quickly.
 * /ls/yc/home/falcon/manage_override.controller.yc needs to be
   cleaned up occasionally.
 * MapReduces don't have CPU reservations and are being throttled.


---------------------

* READ UP:
 * FiberHose
 * WatchTower
 * ThunderDome
 * Life of a Datacenter
 * Clock synchronization at Google
 * go/NforN

--------------------------------

- Fix init script for telebot
- Voice synthesis - Flint
- Add unit tests
- Add docutmentation
- Code style guide
- YATE
- Support from: and reply-to: in e-mails
- message+NUMBER
- International calls
- Alternate PSTN providers
- Bug in messages that include a ( character
- System test
- Load test

----------

$ sudo ethtool -i eth0
driver: tg3
version: 3.65
firmware-version: 5752-v3.10
bus-info: 0000:3f:00.0



Create null route on prod machine.

$ blackhole hsbaby.prodz

$ chubby_list_timestamps ls
Replica         Host   LockServer  ChubbyDNSServer   ChubbyMirror
chubby-ls-000a  lsea37 1194914595  1179203631        1178875436 
chubby-ls-000b  lsjj35 1194914595  1179203631        1178875436 
chubby-ls-000c  lsay31 1194914595  1179203631        1178875436 
chubby-ls-000d  lsfp28 1194914595  1179203631        1178875436 
chubby-ls-000e  lstt17 1194914595  1179203631        1178875436 

------------------

$ blaze build net/eventmanager:all

-----------

Stubby balancer:

Add flag: --export_per_user_statistics

---------

Restart svelte servers serially:

$ bbs --start=svelte --delay=300 servers.chubby.local.qb

---------

Manually reinstalling svelte on new machines.

 $ mdb adsrv -m qbql1 -l 'Machine replacement' -v chubby -t svelte -p
   6297 -g synced --p4reviewers chubby-team

$ mdb adsrv -m qbpa13 -l
   'Machine replacement' -v chubby -t svelte -p 6297 -g synced
   --p4reviewers chubby-team

Edit google/config/servers.local.chubby.qb
 $ ssh produser@qbmcp.prodz.google.com
Warning: Permanently added 'qbmcp.prodz.google.com,10.65.179.11'
   (RSA1) to the list of known hosts.
Warning: Remote host denied X11 forwarding.
Last login: Tue Jan  8 08:33:28 2008 from varick.nyc.corp.google.com
[produser@qbpg11 produser]$ ls
[produser@qbpg11 produser]$ mkdir temp
mkdir: cannot create directory `temp': Permission denied
[produser@qbpg11 produser]$ ls
[produser@qbpg11 produser]$ pwd
/user/produser
[produser@qbpg11 produser]$ ls
[produser@qbpg11 produser]$ ls -l
total 0
[produser@qbpg11 produser]$ cd /root/google/config
[produser@qbpg11 config]$ touch temp
touch: creating `temp': Permission denied
[produser@qbpg11 config]$ cd /tmp
[produser@qbpg11 /tmp]$ ls
colocdistance.data.produser  lilo.conf.old  ssh-produser
colocdistance.data.root      oprofilefs
[produser@qbpg11 /tmp]$ mkdir config
[produser@qbpg11 /tmp]$ cd config/
[produser@qbpg11 config]$ ls
[produser@qbpg11 config]$ cp /root/google/config/serv
Display all 3699 possibilities? (y or n)
[produser@qbpg11 config]$ cp
   /root/google/config/servers.chubby.local.qb .
[produser@

$ /home/build/google/production/assigner/setup_mach.py --force
   --mach=qbql1 servers.chubby.local.qb

-------------

Use crash machine to push configs.

 $ chubby_lsmast ta-crash
taak33 taee15 tatt12 tauu12 tax12
> pts/19 mmuthanna@mmuthanna2:~/work/chubby/google/config
> 0 16:13:12 $ ssh root@taak33
Warning: Permanently added 'taak33,10.112.62.33' (RSA1) to the list of
   known hosts.
Warning: Remote host denied X11 forwarding.
[root@taak33 /root]# 


$ sync baby

--------------------

Emergency request reboot (reqreboot):

$ mdb rqrb -E mach1 mach2

--------------------

Release machines:

$ mdb rmsrv -m qbpa13 -l 'Machine replacement' --p4reviewers
   chubby-team

Re assign machines:

$ mdb assign-machines --newowner machines-transit --machines qbql1
   qbpa13

---------------------

Debian package management

List installed packages.

$ dpkg -l

List files owned by package.

$ dpkg -L package-name

E.g.,

$ dpkg -l | grep java
$ dpkg -L sun-java5-jdk

------------------

Teleauth migration

create teleauth user and group
add www-data to teleauth group

Backup database.
$ pg_dump factor2_1_prod >factor2_1_prod.sql

Install postgres

$ apt-get install postgresql ruby1.8-dev libpg-dev make ghostscript gsfonts
$ gem install postgres

Edit postgresql.conf and enable local listen.

Add line to pg_hba.conf:
local   all         all                               md5

$ su - postgres
$ psql <create_db.sql
ERROR:  role "rails" does not exist
CREATE ROLE
CREATE DATABASE

$ cat create_db.sql
drop user rails;
create user rails password 'r4il5';
create database factor2_1_prod with owner = rails;

Restore db

$ psql -U rails -W factor2_1_prod <factor2_1_prod.sql

Enable FastCGI on lighttpd

Link ruby1.8

# ln -s /usr/bin/ruby1.8 /usr/bin/ruby18

start lighty and troubleshoot

Asterisk fun.

Install asterisk.

Edit sip.conf and extensions.conf.
Edit iax.conf too.

Link agi-bin (/usr/share/asterisk/agi-bin)

Install AGI perl libs.

# perl -MCPAN -e shell
(auto configure)

cpan> install POE
cpan> install Asterisk::AGI
cpan> install YAML
cpan> install POE::Component::IKC

Replace broken POE::Component::Client::TCP.pm

Update lib paths in all perl bins (callmanager, AGI)

Update callmanager.yml configuration.

Add asterisk AMI user.

Update dialer:
factor2_1_prod=> update preferences set value = 'http://teleauth.muthanna.com/phone/service.wsdl' where id = 3;
UPDATE 1

Fixed callmanager:
  Event -> UserEvent

Fix email... exim sucks... postfix was easy peasy
Fix javascript

Correct domains in signup_mailer.rb

--------------------------------

More stubbybalancer hacking.

Get it running on local machine with LB:

bin/balancing/stubby/stubbybalancer --bm_enabled_services="" --bm_server_names=/bns/lm/borg/lm/bns/gslb-prod/backend_manager --hm_client_request_interval_in_ms=-1 --lameduck_delay=1000 --lb_client_namespace=blade --default_deadline=4 --lb_client_withdrawn_backend_delete_timeout_in_secs=60 --lb_list=lmbladelb1.prodz.google.com:9480,lmbladelb2.prodz.google.com:9480 --lbhttprequest_dns_check_timeout_in_ms=30000 --lockservice_use_loas --max_requests=2000 --rtsignals --startup_blackout_period_in_ms=5000 --stubby_services='blogsearch_superroot:5000:is_lb#/bns/ug/borg/ug/bns/blogsearch-prod/blogsearch.superroot.sper/0' --logtostderr


IMPORTANT: LB assignments don't work in corp

---------------------------------

Svelte troubleshooting:

 $ /home/build/static/projects/net/rpc/rpc-analyzer --mode=trace svelte_server.anad11.prodbin.log.BINARY_INFO.20080210-165548.28394 | grep "/ls/.*/meta" | perl -pe 's/.*(\/ls\/.*\/meta).*/$1/' >meta_files.anad11

 $ sort meta_files.anad11 | uniq -c | sort -r > sorted_meta.anad11

one command:

$ /home/build/static/projects/net/rpc/rpc-analyzer --mode=trace svelte_server.hsgh10.prodbin.log.BINARY_INFO.20080209-220900.11149 | grep "/ls/.*" | perl -pe 's/.*(\/ls\/[^"]+)".*/$1/' | sort | uniq -c | sort -r > top_paths.hsgh10


-------------------------------------

lockserv / root / loas / create directory from master

$ lockserv --lockservice_auth_localhost --lockservice_use_proxy=never ls -l -d /ls/pr/traffic/trafficmanager/loadbalancer

# This works better:

master$ lockserv --lockservice_auth_localhost --uid=""  ls -l /ls/global/master/storage

# Newer

$ /home/build/google3/production/chubby/lockserv_admin

# Make sure you're using a new lockserv binary. You can copy it from another machine.

----------------------------

Scores:

# PRIMARY SCORE
#
# mbell 8
# mmuthanna 8
# mmuller 2
# philhutton 3
# rgr 4
# salim 8
# samh 8
# sethamin 1
# tee 2
#
# SECONDARY SCORE
# mbell 2
# mmuthanna 2
# mmuller 3
# philhutton 3
# rgr 2
# salim 0
# samh 2
# sethamin 2
# tee 2

# HOLIDAY SCORE (TODO: add Q2 score)
#
# mbell 3
# mmuthanna 1
# muller 0
# philhutton 0
# rgr 0
# salim 3
# samh 3
# sethamin 0
# tee 0

-------------------------

Recursively change chubby directory access.

$ lockserv ls /ls/eb/gfs/keyhole-eb | grep -v gfs | ruby -pe 'gsub(/^/, "/ls/eb/gfs/keyhole-eb/")' | xargs -n 1 lockserv chacl -R -owner 'mdb/keyhole-co'

-----------------------

Create directory in all cells.

$ /bin/ls -d ?? | ruby -pe 'gsub(/(..)/, "/ls/#{$1}/storage")' | xargs -n 1 lockserv mkdir

$ /bin/ls -d ?? | ruby -pe 'gsub(/(..)/, "/ls/#{$1}/storage/pinax")' | xargs -n 1 lockserv mkdir -owner 'mdb/pinax-co' -write '*' -read '*'

------------------

perforce srcfs fun

Clean up workspace

* Delete client

g4 client -d client-name

* Delete workspace

srcfs workspace
srcfs workspace delete workspace-name


-------------------------------
Convert audio from writely to MP3

----------------------

Asterisk FastAGI information.

172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_network: yes
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_network_script: PageAcknowledgement
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_request: agi://dilemma.nyc:2000/PageAcknowledgement
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_channel: SIP/google-006dc650172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_language: en
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_type: SIP
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_uniqueid: 1209489721.7
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_callerid: 12125656156
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_calleridname: unknown
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_callingpres: 0
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_callingani2: 0
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_callington: 0
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_callingtns: 0
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_dnid: unknown
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_rdnis: unknown
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_context: page-user-with-callback
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_extension: s
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_priority: 2
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_enhanced: 0.0
172.25.209.81: [Tue Apr 29 13:22:06 EDT 2008]: agi_accountcode:


-----

TeleBot TODO

- X-TeleBot-SayIt. (added SpeakIt, updated tests)
- Juggernaut servers.
- SSO - track silences
- Change "delete silence" to POST (done, and add silence)
- "Press 4 to silence page for 10m"
- Add catch blocks for FaultException in xmlrpc.rb
- Regression test.


------------

VIM Tips (vim/vi)

Perforce integration

:!g4 edit %
:!g4 revert %

Gtags:

(Make sure tag daemon is running)

Ctrl-] - Jump to keyword under cursor.
Ctrl-T - Pop stack.

File browser.

:e.

:buffers (list buffers)
:buffer 1 (go to buffer 1)

Web pages
:e http://google.com

or even:

vi http://google.com

Insert executed output into buffer.

:r!date

-----------------

Fri Jun 20 09:52:38 EDT 2008

Stubby Balancer Tests broken

Looks like it's due to LOAS enabeld everywhere

------------------

Adding BNS aggregator configuration

DATED: ~/bin/bnsagg_config mdb-group (without the mdb/ prefix)

NEW: ~build/static/projects/chubby/admin/bnsagg_config --both ${mdb_group}


-------------

BladeService footprint reduction

282 Tasks

All tasks: 1 CPU, 150M RAM
iGoogle tasks: 1.5 CPU, 500 RAM

Total freed: 293 CPUs, 51GB RAM

---------------------

Chubby kernel memory testing:

[root@eba10 /root]# uname -a
Linux eba10 2.6.18-smp-210.10 #1 [4031584] SMP Fri Feb 15 13:51:20 PST 2008 x86_64 unknown

[root@eba10 /root]# cat /proc/meminfo
MemTotal:     16226644 kB
MemFree:        134260 kB
Buffers:         24408 kB
Cached:       14712436 kB
SwapCached:          0 kB
Active:        7682824 kB
Inactive:      7633644 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     16226644 kB
LowFree:        134260 kB
SwapTotal:           0 kB
SwapFree:            0 kB
Dirty:             904 kB
Writeback:         240 kB
AnonPages:      579776 kB
Mapped:         107432 kB
Slab:           728952 kB
PageTables:       2808 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:   8113320 kB
Committed_AS:   755676 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    277280 kB
VmallocChunk: 34359460131 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB

(background grep abc lockserver.???INFO.???...)

[root@eba10 /root]# cat /proc/meminfo
MemTotal:     16226644 kB
MemFree:        128760 kB
Buffers:         23580 kB
Cached:       14741248 kB
SwapCached:          0 kB
Active:        6317692 kB
Inactive:      9026896 kB
HighTotal:           0 kB
HighFree:            0 kB
LowTotal:     16226644 kB
LowFree:        128760 kB
SwapTotal:           0 kB
SwapFree:            0 kB
Dirty:            1172 kB
Writeback:           4 kB
AnonPages:      579692 kB
Mapped:         107412 kB
Slab:           709216 kB
PageTables:       2804 kB
NFS_Unstable:        0 kB
Bounce:              0 kB
CommitLimit:   8113320 kB
Committed_AS:   755736 kB
VmallocTotal: 34359738367 kB
VmallocUsed:    277280 kB
VmallocChunk: 34359460131 kB
HugePages_Total:     0
HugePages_Free:      0
HugePages_Rsvd:      0
Hugepagesize:     2048 kB

-----------------------------

MPM (Building bladeservice MPM package)

$ mpm packageinfo bladeservice/stubbybalancer

Package bladeservice/stubbybalancer
Built versions are [1, 2, 3, 4, 5, 6, 7]
Live version is 3
Labels:
  throttlerversion = 7
  I0912 112152 mpm.py:2732] Success

$ mpm packageinfo -v 7 -d bladeservice/stubbybalancer

Package bladeservice/stubbybalancer

Version 7

Labels
--------------------------------------------------------------------------------
throttlerversion

This version of the package is not the "live" version (3 is live)


Package Definition
--------------------------------------------------------------------------------
{'gfs_owner': 'bladeservice-prod',
 'local_cleanup_mode': 'automatic',
 'local_cleanup_policy': [n_newest_versions(3)],
 'master_cleanup_mode': 'manual',
 'master_cleanup_policy': [n_newest_versions(10)],
 'master_repository': '/gfs/cg/prod/mpm_repo',
 'replicate_repository': 1,
 'replicated_repository_path': '/gfs/%(cell)s/prod/mpm_repo',
 'replication_cells': [cells_from_file('bladeservice/cells')],
 'source_checksums': 'sha1',
 'sources': [file('stubbybalancer', 'bin/stubbybalancer', mode=493)]}

I0912 112401 mpm.py:2732] Success

(Make sure 'stubbybalancer' binary is is current path)
$ mpm build bladeservice/stubbybalancer

$ mpm setlabel bladeservice/stubbybalancer throttlerversion 8


-----------------------------------------------
Mass Bladeservice Update

$ for dc in an ar bf bk bx cg da ea; do echo borgcfg --borguser=bladeservice-prod --skip_confirmation $dc/prod.borg update bladeservice_loas.*; done

--------------

Chubby Namespace for logsaver

/namespace/chubby/yx/logs

Stored in /home/build/google3/production/gfs/namespace/chubby/chubby.namespace

$ fu translatenamespace /namespace/chubby/DC/logs


-- Virtual Borg

Tested with 2.6.27 - latest patches on 27


---------------------------

Spelling Update (Increasing replicas for de)

First:

$ borg --borg=pq --borguser=spell-prod changealloc --size 6 onebox.spell_alloc_de

Then:
stat
edit production/borg/onebox/pq.borg

add 'de' : 6 to lang_replicas.

-----

why multithreaded udp?

it doesn't rely on HTTPServer's UDP implementation, and uses the EventManager,
so it's way faster on multicore machines. The drawback is that HTTP over UDP

-----------------

  // This callback is common to LockServiceWatcher and
  // SvelteWatcher.
  typedef Callback1<const LockServiceWatcher::UserData*> ProxyCallback;

  // This callback is used by LockServiceRecursiveWatcher
  typedef Callback4<LockServiceRecursiveWatcher::EventType,
                    const string*,
                    const LockServiceWatcher::UserData*> RecursiveCallback;


-------------

  Submitted Date        November 5, 2008
  Lab Code      Invoice Number      Tracking Number       Amount
  TBR       095589596       8310555       $10.00
  Cardholder Name       Mohit Cheppudira
  Credit Card       MasterCard
  Credit Card Number      ************4730
  Phone       (646) 462-3450
  E-mail      mohit@muthanna.com


   Remove googlebaseapi from enterprise-marketplace. (146754)   Add fensi -> adgets-directory in ti and pq. (1466157)
     Add riskengine-idverification in eb, fa, po, ya, tw (1465930)



-------------------

Change flags dynamically on running server:

To increase log level:

Add: /varz?flag=v&value=5

Lookup: /varz?flag=v

http://0.bladeservice_loas.load_balancer_generic.bladeservice-prod.pr.borg.google.com:25929/varz?flag=v&value=5

Check all flags:

/varz?flag

----------------------

BabySitter

bootstrap file:
//depot/google/config/services.dc

code:
//depot/google/babysitter/babysitter.py

doc:
https://www.corp.google.com/eng/production/docs/external/babysitter-faq.html


------------------


ta-crash... 

CONSTRAINT_SHARING
AUTO_ASSIGN_SETS

--ls mirror extra flags to include mirroring from global crash.

------------------

DIRT / dirt / DiRt

Backup Wiki:

wiki-dr.corp.google.com

Other docs:

//eng/production/docs/chubby

irc #panic


------------------

More svelte hacking.

~/bin/rpc-analyzer --mode=hoststats --starttime=2009/1/19-09:10 --duration=300 svelte_server.fass20.prodbin.log.BINARY_INFO.20090119-050700.21529
Top 15 hosts sorted by number of requests:

     Count     Req MB      Resp MB   Host:Port
      3550       1.11         0.91   127.0.0.1:9551
       884       0.09         0.09   10.223.110.129:56940
       883       0.08         0.08   10.223.107.6:57802
       764       0.06         0.70   10.223.119.207:56384
       676       0.05         0.51   10.223.122.200:41950
       616       0.04         0.53   10.223.116.198:55053
       580       0.10         0.14   10.223.14.155:46079
       500       0.04         0.52   10.223.112.135:56065
       497       0.08         0.13   10.223.74.73:52876
       483       0.03         0.38   10.223.118.19:45608
       474       0.04         0.45   10.223.104.76:44786
       434       0.03         0.35   10.223.124.81:59588
       373       0.03         0.40   10.223.105.72:50795
       370       0.03         0.39   10.223.116.132:51592
       365       0.03         0.32   10.223.113.193:43415


 $ ~/bin/rpc-analyzer --mode=hoststats --starttime=2009/1/19-09:12 --duration=300 svelte_server.fake18.prodbin.log.BINARY_INFO.20090119-052200.31486
Top 15 hosts sorted by number of requests:

     Count     Req MB      Resp MB   Host:Port
     19774       2.14         3.41   10.223.66.197:56478
      5677       1.89         1.61   127.0.0.1:9551
      2308       0.21         1.94   10.223.77.26:6200
      1414       0.12         0.90   10.223.1.1:6203
      1046       0.07         0.85   10.223.117.129:65031
      1040       0.07         0.87   10.223.103.145:54047
      1011       0.07         0.92   10.223.125.77:49311
       997       0.07         0.91   10.223.123.9:47112
       958       0.09         0.11   10.223.121.10:41394
       934       0.09         0.11   10.223.109.15:37099
       927       0.13         2.22   10.48.255.2:6297
       924       0.09         0.10   10.223.106.70:64258
       920       0.09         0.10   10.223.126.208:61451
       917       0.07         0.78   10.223.113.12:41960
       913       0.07         0.82   10.223.124.16:60240


Top files:

$ wget http://yacd14:6297/clientz?regex=.* -O yacd14
$ cat yacd14 | sort -r -n -k 8,16 | less

-------

ion3 shortcuts

alt-tab
alt-k-tab
ctrl-shift->
ctrl-shift-<
alt-enter
F2
F3

----------

eclipse spaces clean up cruft

$ g4 edit *.h *.cc

$ for f in *.h *.cc; do echo $f; perl -pe 's/\s+$/\n/' $f > /tmp/a; mv /tmp/a $f; done

$ g4 revert -a

----------

Home Address

565 Prospect Pl.
Apt. 10B
Brooklyn, NY 11238

Rental Office (Nancy and Mike): 718 636-3888
Super (Enis): 718 490-7740



----

stubby / stubby2 / Stubby 2 
---------------------------

Outline for Stubby and Blade talk.

RPC:

protobuf
  - request
  - response
  - parameters
    - can be overridden
    - deadline
    - fail_fast
    - duplicate_surpression
    - compression
    - protocol
      - tcp
      - udp / keepalive

server
  - eventmanager
  - httpserver on port (named)

channel
  - tcp / udp
  - loas handshake
  - health checking
    - failure_detection_delay 20.0 s

rpc call
  - return code / deadline
    - status
    - error
    - server_elapsed_time
    - network_rtt
  - cancel / is_cancelled() / RPC::CANCELLED
  - lame_duck
  - streaming
    - GetNextStreamResponse

resolving bns
  - BNS name
    - /bns/DC/borg/DC/bns/USER/JOB/N[.namedport]
    - stored in chubby
    - meta file / tasks_per_file
       string task_name = borg::BorgCell("bx").TaskName("ads-prod",
                          "contentads.tsindex", 0);
       Bank* bank = Bank::NewStub(rpc2::NewClientChannel(task_name));

multiple servers:
  - load balancing
      vector<rpc2::ClientChannel*> children;
      children.push_back(rpc2::NewClientChannel("shrimp:1234"));
      children.push_back(rpc2::NewClientChannel("tuna:1234"));
      children.push_back(rpc2::NewClientChannel("geoduck:1234"));

      rpc2::LoadBalancingPolicy* policy =
        rpc2::LoadBalancingPolicy::New("LeastLoaded");
      rpc2::LoadBalancingChannel* channel =
        new rpc2::LoadBalancingChannel(policy, NULL);
      channel->SetChannels(children);

      // The rest is the same as non-loadbalancing channel.
      Bank* bank = Bank::NewStub(channel);
      RPC rpc;
      BalanceRequest request;
      BalanceReply reply;

      request.set_accountnumber(N);
      bank->GetBalance(&rpc, &request, &reply, NULL);
      rpc.Wait();
  - policies
    - RoundRobin
    - LeastLoaded
    - InverseRTT
    - ErrorAdverse
    - FirstReachable

borg jobs:
  - BNSLoadBalancingChannel
    - watches bns file
    - TargetSelectionPolicy
      - RandomSubset
      - NoFilter
      - NetworkAware

behaviours:
  - fail_fast / deadline
  - lame duck
  - flow control
  


  ----------------------

Transcode DVD

$ transcode -i REQUIEMFORADREAM/ -x dvd -T 1,-1 -o requiem.avi -y xvid --no_split

-T: The title number (1), all chapters (-1)
    Title 1 is usually the main feature.

-a 0: Switch to audio track 0. Try different tracks for different langs.

-s 1.2: Increase volume (gain) by 1.2x.


------------------------------

chubby machine replacement

Replace rcb1 with rcu3

$ mdb ri rcu3

Sometimes you need to manually install the packages:
$ mpm -m rcu3 fetch -a -v 2 chubby/warm_loasd /export/hda3/warm_loasd


--------
Balancer logs

Log file created at: 2009/02/17 09:41:20
Running on machine: gdar20
Binary: Built on Dec 10 2008 07:35:09 (1228923309)
Binary: Built at mmuthanna@dilemma.nyc.corp.google.com:/home/mmuthanna/work/throttler/google3
Binary: Built for gcc-4.3.1-glibc-2.3.6-grte-piii
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg

$BORG_ALLOC_DIR/bladeservice_stubbybalancer/bin/stubbybalancer --balancer_export_client_key=backend.user --balancer_export_service_client_userid_info --balancer_export_service_key=backend --balancer_export_stubby_method_key=backend.method --bm_enabled_services=all --bm_server_names=/bns/gd/borg/gd/bns/gslb-prod/backend_manager --default_deadline=4 --enable_loas_simple_delegation --hm_client_request_interval_in_ms=-1 --lameduck_delay=1000 --lb_client_datacenter=gd --lb_client_namespace=blade --lb_client_withdrawn_backend_delete_timeout_in_secs=60 --lb_list=gdbladelb1.prodz.google.com:9480,gdbladelb2.prodz.google.com:9480 --lbhttprequest_dns_check_timeout_in_ms=30000 --lbv2_client_type=bladeservice-prod_bladeservice_loas.load_balancer_generic --lbv2_primary_server_names=/bns/gd/borg/gd/bns/gslb-prod/locallb-shard0 --lbv2_state=enabled_active --lockservice_use_loas --max_channels_per_backend_cluster=20 --max_requests=2000 --pacemaker_delay=250 --rtsignals --service_acl=/ls/gd/bladeservice/acl/gd_generic.acl --service_acl_never_deny --startup_blackout_period_in_ms=5000 --throttler_address=/bns/gd/borg/gd/bns/throttler/throttler.leaf_throttler --throttler_authorized_identities="bladeservice-prod+throttler" --throttler_client_initial_connect_interval=20000 --throttler_disable_rate_limiting --throttler_port=25830

--throttler_address=/bns/gd/borg/gd/bns/throttler/throttler.leaf_throttler --throttler_authorized_identities="bladeservice-prod+throttler" --throttler_client_initial_connect_interval=20000 --throttler_disable_rate_limiting --throttler_port=26233

-- Evil chat

15:38 -!- evilbot [mmuthanna@dilemma.nyc.corp.google.com] has joined #sre-ny
15:38 <@dorland> evilbot: entertain me
15:38 < evilbot> dorland: don't talk to me, minion
15:59 <@re> philhutton: you'll be glad to know my tubes are fast again.
15:59 < evilbot> that philhutton is a real cheeky bastard
15:59 <@re> evilbot--
15:59 < evilbot> re: don't talk about your master that way, scum
15:59 <@dorland> lol
15:59 <@philhutton> LOL
15:59 <@philhutton> That is truly awesome.
15:59 <@philhutton> evilbot++
15:59 < evilbot> philhutton: don't talk about your master that way, scum
16:00 <@re> yeah, pretty good.
16:00 <@re> hah!
16:00 <@re> stupid evilbot.
16:00 < evilbot> re: don't talk about your master that way, scum
16:00 <@re> brilliant, clever, beautiful evilbot.
16:00 < evilbot> re: don't talk about your master that way, scum
16:00 <@re> evilbot: I don't understand.  Please tell me more!
16:00 < evilbot> re: don't talk to me, minion
16:01 <@philhutton> evilbot: how does don't talk to me, minion make you feel?
16:01 < evilbot> philhutton: don't talk to me, minion
16:01 <@philhutton> evilbot--
16:01 < evilbot> philhutton: don't talk about your master that way, scum
16:04 <@re> lisa++
16:04 <@dorland> evilbot needs more range
16:04 < evilbot> dorland: don't talk about your master that way, scum
16:04 <@dorland> it really is exactly like talking to mo though
16:04 <@dorland> a perfect replica

Kick message:

:mmuthanna!mmuthanna@dilemma.nyc.corp.google.com KICK #sre-ny evilbot :mmuthanna

----------------

Update spellmixer replicas:

Edit dc.borg, and add spellmixer_replicas = n to the service. (grep spellmixer_replicas *.borg for example).

$ borgcfg --borguser=spell-prod bf.borg updateallocs onebox.spellmixer_alloc

$ borgcfg --borguser=spell-prod bf.borg update onebox.spellmixer


dagitses, mbell, mmuller, philhutton, rgr, salim, samh, tee, yuanyuan

-------

oprofile

Ask for root on machine.

First, get vmlinux. (Can't derive from vmlinuz, since symbols stripped)

1. Unpack the rpm manually (this is the usual method)
mkdir boot
rpm2cpio <rpm> | cpio -i --no-absolute-filenames

You'll now have a vmlinux in ./boot

2. Export "KEEP_VMLINUX=1" on rpm install, this will install it to /boot/

or use odo's stuff, which insalls vmlinux

~odo/bin/odobot-push hostname
then on hostname run /data/tmp/odobot/get-oprofile

If you get no samples then you may need to drop the frequency for the event. Try 6000.

Then, in the data, look at summary.txt.

Also run:
$ for f in cpu*; do echo $f":"; grep vmlinux $f | head -10 | awk '{print "\t", $2, $5;}'; echo; echo; done

Also useful:

opreport --callgraph (add it to odo's script for summary.txt)

----------

Bladeservice resources

$ ~samh/borgsearch/bladeservice_usermap.sh  | egrep "quota|cell|bk|tb|wb|ye"

---------

running gooss

./blaze-bin/speech/synthesizer/gooss2/client/synthesizer-tester --ssml cheeky.ssml --encoding MULAW --logtostderr >/tmp/cheeky.raw

 sudo sox -r 16000 -U -1 cheeky/cheeky.raw -r 8000 -1 cheeky.gsm resample

dilemma*CLI> core show file formats
Format     Name       Extensions
------     ----       ----------
g722       g722       g722
ulaw       au         au
alaw       alaw       alaw|al
ulaw       pcm        pcm|ulaw|ul|mu
slin       wav        wav
g723       g723sf     g723|g723sf
slin16     sln16      sln16
slin       sln        sln|raw
ilbc       iLBC       ilbc
slin       ogg_vorbis ogg
adpcm      vox        vox
gsm        wav49      WAV|wav49
h264       h264       h264
g726       g726-16    g726-16
g726       g726-24    g726-24
g726       g726-32    g726-32
g726       g726-40    g726-40
gsm        gsm        gsm
g729       g729       g729
h263       h263       h263

------

$ for dc in ??; do echo $dc; lockserv mkdir /ls/$dc/loadbalancer; lockserv mkdir -owner 'mdb/gslb-prod' -write 'mdb/gslb-prod' -read '*' /ls/$dc/loadbalancer/lbclient; done

---


TeleBot IVR (work/speech)

Build gooss2 server

$ blaze build -c opt speech/synthesizer/gooss2/server:all
$ cp -r -L blaze-bin/speech/synthesizer/gooss2/server $IVR_PATH

Build IVR

$ blaze build -c opt monitoring/telebot/ivr:all
$ cp blaze-bin/monitoring/telebot/ivr/telebot_ivr $IVR_PATH

TAR it up

$ tar -zcvf telebot_ivr.tar.gz $IVR_PATH

Move it to natterbot and untar.

Install crosstools v12 on natterbot. (See moma)

Start server:

$ start-local-server --uid=root

(Ignore LOAS errors).

Warm up server:

$ ./telebot_ivr --uid=root --message="Hello World"

Ownership

User asterisk should be able to:

- write to /var/lib/asterisk/sounds/telebot
- execute telebot_ivr

Asterisk extensions.conf:

[page-user]
exten => s,1,Goto(page-user-festival,s,1)

[page-user-with-callback]
exten => s,1,Goto(page-user-with-callback-flint,s,1)

[page-user-with-callback-flint]
exten => s,1,Answer
exten => s,2,Wait(1)

; Start the IVR
exten => s,3,ExternalIVR(/opt/local/telebot/ivr/telebot_ivr,--uid=root,--message,${Message},--audio_file_path,/var/lib/asterisk/sounds/telebot,--logtostderr)

; If we received an ACK or NACK then return to TeleBot.
exten => s,4,GotoIf($[${Acknowledged} = "1"]?1,1
exten => s,4,GotoIf($[${Acknowledged} = "0"]?1,2

; Else, the IVR failed, failover to old-school festival server.
exten => s,5,Goto(page-user-with-callback-festival,s,2)

; ACK
exten => 1,1,AGI(agi://${Callback}/PageAck?ticket=${Ticket}&username=${Number})
exten => 1,2,Background(telebot/ack)
exten => 1,3,Hangup

; NACK
exten => 2,1,AGI(agi://${Callback}/PageNack?ticket=${Ticket}&username=${Number})
exten => 2,2,Background(telebot/nack)
exten => 2,3,Hangup

; Quit
exten => 3,1,Hangup

[page-user-festival]
exten => s,1,Wait(1)
exten => s,2,Flite(${Message})
exten => s,5,Wait(1)
exten => s,6,Hangup

[page-user-with-callback-festival]
exten => s,1,Wait(1)
exten => s,2,Set(TIMEOUT(response)=10)
exten => s,3,Background(telebot/intro)
exten => s,4,Wait(1)
exten => s,5,Flite(${Message})
exten => s,6,Wait(1)
exten => s,7,Background(telebot/menu)
exten => s,n,WaitExten

exten => 1,1,AGI(agi://${Callback}/PageAck?ticket=${Ticket}&username=${Number})
exten => 1,2,Background(telebot/ack)
exten => 1,3,Hangup

exten => 2,1,AGI(agi://${Callback}/PageNack?ticket=${Ticket}&username=${Number})
exten => 2,2,Background(telebot/nack)
exten => 2,3,Hangup

exten => 3,1,Goto(s, 4)

;; Timeout
exten => t,1,Goto(s, 1)


---------------

registry*=1,throttler*=1,backend_rebalancer*=1 

/varz?flag=vmodule&value=lock*=5



I0504 10:03:55.350534  4411 lockservice_session.cc:581] CheckCachingNoInvalidate returning 1
I0504 10:03:55.350606  4411 lockserviceimpl.cc:1876] GetVersionInfo /home/ewiseblatt/throttler/qa/master_lock.primary session 18038668159
I0504 10:03:55.350646  4411 lockserviceimpl.cc:1884] GetVersionInfo
I0504 10:03:55.350671  4411 lockservice_session.cc:866] RepRPCRepeat called for GetStat on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary ls_rpc 0x8e6c380 2147483647 session id 433303b7f this->server=2
I0504 10:03:55.350721  4411 lockservice_session.cc:694] used stub 0x8e7a900
I0504 10:03:55.367027 14669 lockservice_session.cc:930]  RepRPCDone called for GetStat on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary ls_rpc 0x8e6c380 retries 2147483647 rpc status 0 reply status 0 reply error 0
I0504 10:03:55.367089 14669 lockserviceimpl.cc:2015]  in CacheDone for operation GetStat0 0 0 1
I0504 10:03:55.367128 14669 lockserviceimpl.cc:2050] GetStat cache set for session  18038668159
I0504 10:03:55.367262  4411 lockservice_session.cc:581] CheckCachingNoInvalidate returning 1
I0504 10:03:55.367297  4411 lockserviceimpl.cc:2384] TryAcquireExclusive
I0504 10:03:55.367323  4411 lockservice_session.cc:866] RepRPCRepeat called for TryAcquireExclusive on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary ls_rpc 0x9521380 2147483647 session id 433303b7f this->server=2
I0504 10:03:55.367360  4411 lockservice_session.cc:697] used stub 0x8e7a900
I0504 10:03:55.385572 14669 lockservice_session.cc:930]  RepRPCDone called for TryAcquireExclusive on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary ls_rpc 0x9521380 retries 2147483647 rpc status 0 reply status 0 reply error 0
I0504 10:03:55.385617 14669 lockserviceimpl.cc:2015]  in CacheDone for operation TryAcquireExclusive0 0 0 1
I0504 10:03:55.385644 14669 lockserviceimpl.cc:2050] TryAcquireExclusive cache set for session  18038668159
I0504 10:03:55.385715  4411 masterelection2.cc:445] LockService TryAcquireExclusive status: /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary: success
I0504 10:03:55.385739  4411 masterelection2.cc:244] Release locks
I0504 10:03:55.385750  4411 masterelection2.cc:246] Release lock 0 ,state 2
I0504 10:03:55.385778  4411 lockserviceimpl.cc:2416] ReleaseExclusive
I0504 10:03:55.385798  4411 lockservice_session.cc:866] RepRPCRepeat called for ReleaseExclusive on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary ls_rpc 0x9520680 2147483647 session id 433303b7f this->server=2
I0504 10:03:55.385826  4411 lockservice_session.cc:698] used stub 0x8e7a900
I0504 10:03:55.385859  4411 masterelection2.cc:246] Release lock 1 ,state 4
I0504 10:03:55.403840 14669 lockservice_session.cc:930]  RepRPCDone called for ReleaseExclusive on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary ls_rpc 0x9520680 retries 2147483647 rpc status 0 reply status 0 reply error 0
I0504 10:03:55.403945 14669 lockserviceimpl.cc:2084]  in CacheInvalidate for operation LockService ReleaseExclusive status: success on /ls/test/home/ewiseblatt/throttler/qa/master_lock.primary
I0504 10:03:55.403964 14669 lockserviceimpl.cc:2086] 0 0 0 1



I0504 10:11:50.543654 29915 lockservice_session.cc:581] CheckCachingNoInvalidate returning 1
I0504 10:11:50.543701 29915 lockserviceimpl.cc:1876] GetVersionInfo /home/ewiseblatt/throttler/qa/master_lock.secondary session 18060708389
I0504 10:11:50.543735 29915 lockserviceimpl.cc:1884] GetVersionInfo
I0504 10:11:50.543758 29915 lockservice_session.cc:866] RepRPCRepeat called for GetStat on /ls/test/home/ewiseblatt/throttler/qa/master_lock.secondary ls_rpc 0x966aa00 2147483647 session id 434808a25 this->server=5
I0504 10:11:50.543786 29915 lockservice_session.cc:694] used stub 0x92a5240
I0504 10:11:50.559866  4964 lockservice_session.cc:930]  RepRPCDone called for GetStat on /ls/test/home/ewiseblatt/throttler/qa/master_lock.secondary ls_rpc 0x966aa00 retries 2147483647 rpc status 0 reply status 0 reply error 0
I0504 10:11:50.559917  4964 lockserviceimpl.cc:2015]  in CacheDone for operation GetStat0 0 0 1
I0504 10:11:50.559947  4964 lockserviceimpl.cc:2050] GetStat cache set for session  18060708389
I0504 10:11:50.560079 29915 lockservice_session.cc:581] CheckCachingNoInvalidate returning 1
I0504 10:11:50.560137 29915 lockserviceimpl.cc:2384] TryAcquireExclusive
I0504 10:11:50.560173 29915 lockservice_session.cc:866] RepRPCRepeat called for TryAcquireExclusive on /ls/test/home/ewiseblatt/throttler/qa/master_lock.secondary ls_rpc 0x966a380 2147483647 session id 434808a25 this->server=5
I0504 10:11:50.560238 29915 lockservice_session.cc:697] used stub 0x92a5240
I0504 10:11:50.578548  4964 lockservice_session.cc:930]  RepRPCDone called for TryAcquireExclusive on /ls/test/home/ewiseblatt/throttler/qa/master_lock.secondary ls_rpc 0x966a380 retries 2147483647 rpc status 0 reply status 0 reply error 0
I0504 10:11:50.578608  4964 lockserviceimpl.cc:2015]  in CacheDone for operation TryAcquireExclusive0 0 0 1
I0504 10:11:50.578636  4964 lockserviceimpl.cc:2050] TryAcquireExclusive cache set for session  18060708389
I0504 10:11:50.578701 29915 masterelection2.cc:445] LockService TryAcquireExclusive status: /ls/test/home/ewiseblatt/throttler/qa/master_lock.secondary: success
I0504 10:11:50.578725 29915 masterelection2.cc:244] Release locks
I0504 10:11:50.578735 29915 masterelection2.cc:246] Release lock 0 ,state 4
I0504 10:11:50.578743 29915 masterelection2.cc:246] Release lock 1 ,state 2


------

RPC ACL (push acl / pushacl)

$ borgcfg --borguser=bladeservice-prod prod.borg push_acl bladeservice_loas.*


-- for alexk (ymr20)

cpu11.txt:


cpu12.txt:
         3.4318 copy_user_generic_asm
         2.5250 dev_queue_xmit
         1.2731 kmem_cache_free
         1.2006 kfree
         0.9176 __netif_receive_skb
         0.8649 schedule
         0.7818 tcp_v4_rcv
         0.6852 ep_poll_callback
         0.4692 process_backlog
         0.4567 futex_wake


cpu13.txt:
         3.2641 copy_user_generic_asm
         2.6723 dev_queue_xmit
         1.3409 kmem_cache_free
         1.2750 kfree
         0.9271 __netif_receive_skb
         0.9124 schedule
         0.8178 tcp_v4_rcv
         0.7263 page_referenced_one
         0.7252 page_check_address
         0.6881 ep_poll_callback


cpu14.txt:
         3.4604 copy_user_generic_asm
         2.3733 dev_queue_xmit
         1.1888 kmem_cache_free
         1.1222 kfree
         0.8650 __netif_receive_skb
         0.8018 schedule
         0.7530 tcp_v4_rcv
         0.6307 ep_poll_callback
         0.4494 futex_wake
         0.4412 process_backlog


cpu15.txt:
         3.6786 copy_user_generic_asm
         2.5472 dev_queue_xmit
         1.2648 kmem_cache_free
         1.2201 kfree
         0.9217 __netif_receive_skb
         0.8883 schedule
         0.7934 tcp_v4_rcv
         0.6792 ep_poll_callback
         0.6446 cpuacct_count_states
         0.4740 futex_wake



------------

- Graphing dependecies for a google3 app

$ blaze query "deps(balancing/throttler/server/internal:throttler)" --output=graph >/tmp/x.dot

$ dot -Tsvg /tmp/x.dot >/tmp/foo.svg
$ dot -Tpdf /tmp/x.dot >/tmp/foo.pdf

----

chubbydnsserver / chubby dns server

$ dig master.ya.gfs.ya.ls.google.com

point to specific chubby DNS server:
$ dig master.pr.gfs.pr.ls.google.com @prhc40

------------

Kindle / kindle

Mounting:

$ sudo mount /dev/sdd1 /tmp/kindle

Unmounting:

$ sudo umount /tmp/kindle
$ sudo eject /dev/sdd1

Merge PDF files:

$ gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite \
  -sOutputFile="Stanford CS229 Notes.pdf" \
  cs229-notes1.pdf cs229-notes2.pdf ...

-------------------------------------

new throttler service configuration

$ lockserv touch /ls/global/balancing/throttler/configs/fastnet

$ for dc in eb fg gh ia pr po qc ti ya yq; do lockserv chacl -owner mdb/throttler -write mdb/redmeat-sre /ls/$dc/balancing/throttler/configs/fastnet; done

$ for dc in eb fg gh ia pr po qc ti ya yq; do echo lockserv cp /tmp/stub /ls/$dc/balancing/throttler/configs/fastnet; done

The stub:

domain_configuration <
  name: "fastnet_service"
  owners: "fastnet"
  realm: "global"
>

--------------------------------------

Generate new throttler configs by running:

 $ /home/build/static/projects/bladeservice/blade_update.par.

If the database is stale:

 $ scp -r mmuller:/tmp/blade_update.data /tmp

This will g4 edit the throttler configs in your p4 client.

Swapping balancer shards for a user:

Edit ~mmuthanna/bin/blade_swap_balancers.py

 $ /home/build/static/projects/bladeservice/blade_man.par script blade_swap_balancers.py

-------------------

ldap search

 $ ldapsearch -LLLx -b 'ou=people,dc=google,dc=com'

Specific user:
$ ldapsearch -LLLx -b 'uid=mbell,ou=people,dc=google,dc=com'

Automounts / home directory / mount
$ ldapsearch -xLLL -b 'ou=Automounts,dc=google,dc=com' cn=mmuthanna

 --------------------

Babysitter tools

 setup_mach
 assigner
 syncdb
 list_config
 babysitter.py

---------------------

Asterisk SIP update (slack / corp):

Production:
//depot/ops/corp/slack/roles/telebot/files/etc/asterisk/

Test:
//depot/ops/corp/slack/roles/telebot/files.test/etc/asterisk/

New AME gateway: pstngw1.nyc.corp.google.com


-------------------------
Global chubby memory findings:

- Negatively cached entries are a red-herring.

- Session count from Java binaries is significant (but not a contributing factor)


--------------------------

mount ipod

$ sudo mount -t hfsplus /dev/sdd2 /tmp/ipod
$ sudo umount /tmp/ipod
$ sudo eject /dev/sdd2

----------------

Thu Nov 12 15:47:53 EST 2009

New chubby stuff:

Alert tuning, Daily alerts.
Chubby on borg
Svelte scaling, network overload.

----------------------

PS with wait channel

ps -elf

find the relevant pid and do something like:

while true; do cat /proc/pid/trace; sleep 1; done

------------------------------

odo's message

the difference between minor and major page faults are whether the kernel has to do IO to get the data into memory before it can set up the page table mapping.

the methods used to map executables/shared libraries into the address space are the same as those used by mmap(2) syscall.  so yeah you'll get major page faults here if the executable needs to be read in to satisfy a page fault.

on linux all memory allocation (brk/sbrk/mmap(MAP_ANON)/shmget) uses deferred allocation and you end up with a minor page fault for every page the first time its written to (all allocated pages initially point to a shared read-only page full of zeroes).

but ... that may not be the problem we're seeing here.

one thing you can do is use the "wchan" output modes from ps ... "ps -elf" for example will give a very short truncated name of where the processes are waiting in the kernel.  you'll need to mess around with some of the other ps formatting outputs to get more detail.

what's even better probably is to "cat /proc/pid/trace" ... that'll give the kernel traceback for that pid.  (you'll need to figure out the tid actually but you can get that from /topz or /threadz).

when a linux task is in D "uninterruptible sleep" state it can't respond to signals, and that's why /wallz and /threadz can't get the stack traces -- they rely on signals being sent to to the threads to initiate stack traces.  the D state tasks are probably stuck somewhere in the kernel waiting on a spinlock held by something else... this is usually where i'd start asking for oprofiles but maybe /proc/pid/trace is the best we can do without root access.

find the relevant pid and do something like:

while true; do cat /proc/pid/trace; sleep 1; done

-dean

p.s. there are opportunities here to add more profilers to google3 which don't have this problem with D state... via /proc/pid/trace and /proc/pid/stat which exposes the userland and kernel instruction pointers (but i don't think it exposes userland stack pointer in x86_64).


----------------

Deleted nodes in /ls/test/tmp older than 1440 minutes.

Files deleted: 173814
Files skipped: 18998
Directories deleted: 80577
Directories skipped: 10113
Chubby errors: 1228
Started at: 2009-11-30 13:36:08.218750
Total time: 15:20:18.016493


-------------------------

analyze throttler configs

~mmuller/bin/throttler_analyze_configs

push throttler configs for bladeserice

~/bin/throttler_config_pusher.sh (this works even now)
-------------------------

Printing one sided / one-sided

use evince and save yourself the pain.

lp -d queens-plaza -n 2 -o sides=one-sided

-n = number of copies

-------------------------------

BigStore / bigstore

 $ export AWS_S3_HOST=commondatastorage.googleapis.com
 $ export AWS_ACCESS_KEY_ID=16205552212797158517
 $ export AWS_SECRET_ACCESS_KEY="3KFB4hoG2jw2Q+MOyqSe/EETNpshfJBQFlyjHHQA"
 $ ./s3cmd.rb createbucket music

----------------------------------

Garbage collect forever: 

$ while [ 1 ]; do ~mmuthanna/bin/chubby_gc.par --path /ls/test/tmp --sleep_between_deletes_s 0.1 --max_age_minutes 720 --force --quiet; sleep 60; done


Delete large numbers of files in Chubby:

 $ for f in `lockserv ls /ls/yq/workflow | grep patchpanel_testing_gfstmp`; do echo lockserv rm /ls/yq/workflow/$f; done

Or, directly on machine:

 for f in `lockserv --lockservice_use_proxy=never --lockservice_auth_localhost --uid '' ls /ls/yr/config/cdd/yr | egrep 'brandadmetr.+test'`; do /root/google/bin/lockserv --lockservice_use_proxy=never --lockservice_auth_localhost --uid '' rm -R /ls/yr/config/cdd/yr/$f; done


$ ~/bin/svelte_top_filehogs.py --starttime=09:25 --duration=1200 svelte_server.yqa5.prodbin.log.BINARY_INFO.20100108-060204.6631
Running: /usr/local/symlinks/rpc-analyzer --mode=trace --trace_maxlinesize 50000 --starttime=09:25 --duration=1200 svelte_server.yqa5.prodbin.log.BINARY_INFO.20100108-060204.6631

Processed 1768725 lines.

Top 15 clients by number of unique files:
52777 svelte_server
781 loasd
169 com.google.testing.junit.runner.GoogleTestRunner
130 bigtable_tablet_server:kansas-tech/bigtable-tablet-server-public
128 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_12disk_csborglet
102 com.google.feedburner.frontend.feed.FeedServer
102 gfs_master
101 stubbybalancer:bladeservice-prod/bladeservice_loas.load_balancer_generic
97 0x2aaa7d2b0687b00a (10.176.135.6:61112)
84 bigtable_tablet_server:bt-sre/btservice-srv.btserver_8G_64
84 gws:xiaopanzhang/baseline.frontend.gws
82 com.google.storage.megastore.replication.server.ReplicationServer
78 old-loasd64
62 bigtable_tablet_server:bt-sre/btservice-mix.btserver_8G_64



$ ~/bin/svelte_top_filehogs.py --starttime=09:25 --duration=1200 svelte_server.yqhd9.prodbin.log.BINARY_INFO.20100108-060903.10005
Running: /usr/local/symlinks/rpc-analyzer --mode=trace --trace_maxlinesize 50000 --starttime=09:25 --duration=1200 svelte_server.yqhd9.prodbin.log.BINARY_INFO.20100108-060903.10005

Processed 1633555 lines.

Top 15 clients by number of unique files:
43583 svelte_server
795 loasd
760 borgmon:grid-mon/datacenter-test.clientmon-scraper
272 gfs_master 
191 com.google.testing.junit.runner.GoogleTestRunner
190 cluster_beacon.par:bwenforcer-prod/monitoring.cluster_beacon
130 bigtable_tablet_server:kansas-tech/bigtable-tablet-server-public
128 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_12disk_csborglet
121 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_borglet
112 com.google.orkut.OrkutServer
102 stubbybalancer:bladeservice-prod/bladeservice_loas.load_balancer_generic
86 bigtable_tablet_server:bt-sre/btservice-srv.btserver_8G_64
74 gws_rollback_and_labrat_binary
73 com.google.groups2.frontend.GroupsServer


$  ~/bin/svelte_top_filehogs.py --starttime=09:25 --duration=1200 svelte_server.yqmq3.prodbin.log.BINARY_INFO.20100108-061359.21054
Running: /usr/local/symlinks/rpc-analyzer --mode=trace --trace_maxlinesize 50000 --starttime=09:25 --duration=1200 svelte_server.yqmq3.prodbin.log.BINARY_INFO.20100108-061359.21054

Processed 1515950 lines.

Top 15 clients by number of unique files:
13112 cdd_watcher:uetliborg/uetli_canary.cdd_watcher
839 loasd
567 colossus_dashboard:colossus/dashboard
238 old-loasd64
218 netradar:netops/netradar3.netradar
159 com.google.testing.junit.runner.GoogleTestRunner
130 bigtable_tablet_server:kansas-tech/bigtable-tablet-server-public
128 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_12disk_csborglet
114 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_borglet
112 com.google.orkut.OrkutServer
99 bigtable_tablet_server:bt-sre/btservice-srv.btserver_8G_64
97 0x82a529c81503b10a (10.177.3.21:50788)
96 0x437752771006b10a (10.177.6.16:42915)
93 0x5f3b87300725b10a (10.177.37.7:43049)


 $ ~/bin/svelte_top_filehogs.py --starttime=09:25 --duration=1200 svelte_server.yqne39.prodbin.log.BINARY_INFO.20100108-060529.7641
Running: /usr/local/symlinks/rpc-analyzer --mode=trace --trace_maxlinesize 50000 --starttime=09:25 --duration=1200 svelte_server.yqne39.prodbin.log.BINARY_INFO.20100108-060529.7641

Processed 1793772 lines.

Top 15 clients by number of unique files:
29997 cdd_watcher:uetliborg/uetli_canary.cdd_watcher
803 loasd
761 borgmon:grid-mon/datacenter.clientmon-scraper
186 com.google.testing.junit.runner.GoogleTestRunner
130 bigtable_tablet_server:kansas-tech/bigtable-tablet-server-public
125 stubbybalancer:bladeservice-prod/bladeservice_loas.load_balancer_generic
104 com.google.feedburner.frontend.feed.FeedServer
102 borgmon:prodmon/datacenter.metamon-borgmon
100 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_12disk_csborglet
97 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_32gb_borglet
94 bigtable_tablet_server:bt-sre/btservice-srv.btserver_8G_64
94 bigtable_tablet_server:kansas-tech/bigtable-tablet-server_16gb_12disk_csborglet
93 com.google.ccc.groups.index.server.CommonGroupsApiServer
92 gfs_master

--------------------

----------

Boost / boost

Aptitude install everying with "boost" in it. And it just works!

$ g++ simple.cpp

--------------

Unit tests.

Online test. Build normally:

#define BOOST_TEST_MAIN
#include <boost/test/included/unit_test.hpp>


Otherwise build with -l:

g++ unittest.cc -lboost_unit_test_framework

(Will not link, intentional)

Either use static linking:

$ g++ unittest.cc /usr/lib/libboost_unit_test_framework.a

or add this to allow main() in dynamic linked executable:

#define BOOST_TEST_DYN_LINK

-----------

MacVim

$ mvim scp://mohit@muthanna.com/TODO


--------------------

Interview questions

- Divide 2 integers without divide?

 Repeated subtraction = O(a/b)
 Shift + repeat subtraction = O(log a)

- Implement stack with a max function.

 Need two stacks to make all operations O(1)

- Given hash function returning value between [0, 2^32) with an even
  distribution, how many random items can be passed through before there's
  a 50% chance of collision? (Birthday paradox)

- Existence of an element in a circularly sorted array?

  e.g., (2,3,4,5,1)

  One way... find breaking point n. Reindex array so accessing element i
  is ((i + n) % length)

  To find breaking point, realize that it should be < first (0th) elem.

- Design an LRU cache?

  LRU ordered double linked list + Hash (with pointers to list)

- Compare ranking algorithms? (e.g., use expensive algorithm to test cheap one)

- Do two rectangles intersect?
  (intersection in 1d, then 2d... if X-axis intersect && Y-axis intersect)

- Find the intersection between two sorted integer arrays.

- Remove all occurrences of char c from string s in-place (no strcpy)
    void RemoveChar(char *s, char c);

- Implement a reference counted string.
  (Need InternalString inner class to keep refcount and data).

- Split camelcase strings

-  Intersection of two arrays
  + Sorted merge (not necessarily the optimal solution)
  + If one list is significantly smaller in size than the other

- Longest self terminating program

- Given an array of ints, tell me how to find two values that sum to a
specified value (from https://ideas.corp.google.com/InterviewQuestions/view.php?idea=57)

- Design a database supporting insert, delete, lookup, iterate.
  Scope out the problem. (b-tree??) 

- Simulate a dice using a coin

- Find the minimum and maximum of a list of integers

 if (a < min) {
  min = a
 }
 if (min > max) {
  max = a
 }

 O(2N) comparisons

 There is a O(3/2N) comparisons algorithm:

 min = 0; max = 0;
 loop until no more:
  read a, b
  if (a >= b):
    if (a > max): max = a
    if (b < min): min = b
  else:
    if (b > max): max = b
    if (a < min): min = a

Sort, then setup two pointers, one at each end.

- Hand shaking problem: http://www.corp.google.com/~eisar/interview/q4.html
- Colliding robots problem: http://www.corp.google.com/~sankar/collidingrobots.html. Similar to finding a cycle in a linked list. One step, two steps.

- What does this do? (And find all the bugs)

#define FUNC(x,y) {     \ 
    (x) ^= (y);         \ 
    (y) ^= (x);         \ 
    (x) ^= (y);         \ 

int main(int argc, char **argv) {
    srand48(0);

    const size_t n = 1000;
    int *tab = (int*)malloc(n*sizeof(int));
    for(int i = 0; i < n; ++i) tab[i] = i;

    for(int i = 0; i < n; ++i) {
        int i1 = (int)ceil(n*drand48());
        int i2 = (int)ceil(n*drand48());
        FUNC(tab[i1], tab[i2]);
    }

    for(int i = 0; i < n; ++i) printf("%d ", tab[i]);
    printf("\n");
    return 0;
}

  + seed is 0
  + check malloc NULL
  + no free
  + floor instead of ceil (range screwey)
  + macro expansion XORs same mem when i1 == i2 (extra 0s)
  + not a good shuffle

- Finding top k elements out of n.. selection. / median
  + Sometimes it may be cheaper to sort then select, e.g., if kn > n log n
  + Faster, if the top K don't have to themselves be sorted.
  + Like quicksort, partition with pivot, and search the partition that
    contains the Kth element O(2N)

- Find median value in file (more data than mem) / Streaming
  + divide range into buckets
  + track bucket size... median could be average (approx.)

- Find the mayor. (Everyone knows him, but he knows noone)
  + this is probably a simple graph search problem.

- Determine integer palindromes (1249421)

- Build queues with constant number of stack.
  - Use two stacks... push into one.
  - Transfer (pop-push) to other (only when other is empty)
  - pop from other

- Merge k lists
  - tree of merges


C++

- Prevent creation of objects on stack (hide constructor, factory func)
- Prevent creation of objects on heap (overload new)
- Virtual functions.
- Double dispatch.

------------

xmonad / XMonad

located in ~/.cabal/bin/xmonad
configs in ~/.xmonad/xmonad.hs

Rebuilding configs:
$ xmonad --recompile
<Mod> q

Navigating

- <Mod> Space : mess with layout
- <Mod> j/k: move around
- <Mod> <Shift> <Enter> : New terminal
- <Mod> <Shift> j/k: Move windows around
- <Mod> Click: Drag windows (and make floating)
- <Mod> t: unfloat

- <Mod> <1-9> Shift workspace
- <Mod> <Shift> <1-9> shift window to workspace (9 is good for minimize)
- <Mod> w/e Switch screens (monitors)
- <Mod> <Shift> w/e: Move windows across workspaces
- <Mod> p start dmenu (this takes a while, the first time)
----------------


Sat Apr  4 13:20:24 EDT 2009

vim stuff
  * Ctrl-[ is like <ESC>
  * set spell to turn on spelling
  * set number to show line numbers
  * Folding:
    - set foldmethod=indent
    - zo, zc: open and close folds
    - zR: unfold entire file
    - zM: fold entire file

     zf#j  creates a fold from the cursor down  #  lines.
     zf/string creates a fold from the cursor to string .
     zj moves the cursor to the next fold.
     zk moves the cursor to the previous fold.
     zo opens a fold at the cursor.
     zO opens all folds at the cursor.
     zm increases the foldlevel by one.
     zM closes all open folds.
     zr decreases the foldlevel by one.
     zR decreases the foldlevel to zero -- all folds will be open.
     zd deletes the fold at the cursor.
     zE deletes all folds.
     [z move to start of open fold.
     ]z move to end of open fold.

  * vim tabs
    + :tabe, :tabn, :tabp, :tabc, :tab split

  * visual mode
    + v, shift-v (lines), ctrl-v (block)

  * ctrl-n, ctrl-p: auto complete based on what is in the current file

---------------------------------

LVM / lvm

pvdisplay / vgdisplay / lvdisplay

--------------------

ffmpeg / get movie information

$ ffmpeg -i video.avi

ffmpeg / mov / movie conversion

$ ffmpeg -i Cry\ Baby.MOV -acodec copy -vcodec copy -ss 00:00:35 -t 00:01:10 crybaby.mov

ffmpeg / mov / avi / increase volume (use -vol, 256 is 100%)

$ ffmpeg -i Mini\ Mo\ Blues.mov -acodec mp2 -ab 192k -ar 48000 -ac 2 -vol 512 -vcodec copy mini.avi

ffmpeg / change audio track

$ ffmpeg -i Mini\ Mo\ Blues.mov -i mini_new.wav -map 0:0 -map 1:0 -vcodec copy -acodec copy  minimo.avi

ffmpeg / extract audio

$ ffmpeg -i source_video.avi -vn -ar 44100 -ac 2 -ab 192 -f mp3 sound.mp3:w


--------------------

google maps / chart / dynamic icons / markers

    marker.setIcon("http://chart.apis.google.com/chart?" +
      "chst=d_map_pin_icon_withshadow" +
      "&chld=landslide|DDDDDD");

    marker.setIcon("http://chart.apis.google.com/chart?" +
      "chst=d_map_pin_letter_withshadow" +
      "&chld=" + color_code["grade"] +
      '|' + color_code["bgcolor"] +
      "|" + color_code["textcolor"]);

    marker.setIcon("http://chart.apis.google.com/chart?" +
      "chst=d_map_pin_icon_withshadow" +
      "&chld=location|" + color_code["bgcolor"]);

    marker.setIcon("http://chart.apis.google.com/chart?" +
        "chst=d_text_outline" +
        "&chld=" + color_code["bgcolor"] +
        "|18|h|" + color_code["textcolor"] +
        "|b|" + rspm);

    marker.setIcon("http://chart.apis.google.com/chart?" +
        "chst=d_simple_text_icon_above" +
        "&chld=" + rspm +
        "|18|" + color_code["bgcolor"] +
        "|location|24|" + color_code["bgcolor"] +
        "|" + color_code["textcolor"]);

    marker.setIcon("http://chart.apis.google.com/chart?" +
        "chst=d_simple_text_icon_above" +
        "&chld=" +
        "|16|FF0000|repair|24|444444|444444");

    marker.setIcon("http://chart.apis.google.com/chart?" +
      "chst=d_map_pin_icon_withshadow" +
      "&chld=repair|888888");

--------------------------

- rc.d rc2.d runlevel service

$ update-rc.d -f quagga remove

$ update-rc.d -f quagga stop 19 0 1 2 3 4 5 6

$ rcconf

---------------------

mohit@sylar:~$ mkdir Private
mohit@sylar:~$ ecryptfs-setup-private 
Enter your login passphrase: 
Enter your mount passphrase [leave blank to generate one]: 

************************************************************************
YOU SHOULD RECORD THIS MOUNT PASSPHRASE AND STORE IN A SAFE LOCATION:
sylar: 687fb2d23da2446c792f508d0dcf17c9
evil: d5b6518837c1abb5b7aefa1818218378
THIS WILL BE REQUIRED IF YOU NEED TO RECOVER YOUR DATA AT A LATER TIME.
************************************************************************

Mount:
/home/mohit/.Private on /home/mohit/Private type ecryptfs (ecryptfs_sig=3e99bcc6df67c8ba,ecryptfs_fnek_sig=2604706e46f56090,ecryptfs_cipher=aes,ecryptfs_key_bytes=16)


Warning: Using default salt value (undefined in ~/.ecryptfsrc)
Warning: Using default salt value (undefined in ~/.ecryptfsrc)

Done configuring.

Testing mount/write/umount/read...
Testing succeeded.

Logout, and log back in to begin using your encrypted directory.

-----------------

To use:

$ ecryptfs-mount-private

(Enter login password)

-------------------------------

latex on osx

$ port install texlive

$ latex hello.tex

$ dvips hello.dvi OR dvipdfm hello.dvi

------------------------------

git scm git-core

List remote URLs of working repo.

$ git remote -v

----------------------------

max osx bashrc

Add .bash_profile with:

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

-----------------------------

ls --color (for dark background)

export LSCOLORS=Exfxcxdxbxegedabagacad

--------


pre.prettyprint {
  padding: 5px;
  border: 5px solid #494;
  font-size: 12px;
}


Tue Apr 13 12:29:40 EDT 2010

git parsing

function parse_git_dirty {
  last_line = $(git status 2> /dev/null | tail -n1)
  [[ $(git status 2> /dev/null | tail -n1) != "nothing to commit (working directory clean)" ]] && echo "*"
}

# Get the current git branch name (if available)
git_prompt() {
  ref=$(git symbolic-ref HEAD 2>/dev/null | cut -d'/' -f3)
  if [ "$ref" == "" ]
  then
    echo $ref
  else
    echo "($ref$(parse_git_dirty)) "
  fi
}

-----------------------------

ubuntu default editor

$ sudo update-alternatives -config editor

$ sudo update-alternatives --all


----------------------

(Open internet connections, better than netstat -nap)

# lsof -i

----------------------

gnu screen

$ screen -X title "some title" (aliased to stitle)

Ctrl-a M - Monitor screen for activity.
Ctrl-a _ - Monitor screen for silence.

if [-n "$STY"]; then
    screen -X title "foo"
    screen -X monitor on
fi

------------------------

git list unpushed branches

diff the following:

> 0 (master) $ git branch -r
  origin/HEAD -> origin/master
  origin/master

> 0 (master) $ git branch -r --contains HEAD
  origin/HEAD -> origin/master
  origin/master

Also check unmerged branches:

$ git branch --no-merged

----------------------------

Setup tracking branches for automatic 'git pull'

$ git config branch.master.merge master
$ git config branch.master.remote origin
$ git pull

or as of git 1.7:

$ git branch --set-upstream master origin/master

----------------------------

git remove files from repository forever

$ git ls-files *.o
$ git filter-branch -f --index-filter 'git update-index --remove filename' HEAD
$ git push --force --verbose --dry-run
$ git push --force --verbose

--------------------------

oncall bonus calculation

$ cd /g3/ads/production/bonus

$ ./sre_oncall_bonus.py --oncall_file oncall.chubby --start_date 2010-01-01 --end_date 2010-03-31 --time_offset 9
-----

Hyperic

It does traditional systems / status based monitoring:

- Tivoli / Openview / CA
- SNMP / SMS / 
- monitoring and performance
- top -> down.... application centric.
- rich suite of metrics and diagnostics.
- network devices?... can do most of monitoring network devices...

- Used as a complimentary tool... typically.

Q. hardware / software / database?
  - db: mysql, oracle
  - os: versatile
Q. IPv6
Q. SNMPv3 / IPDR
Q. Can tie back into ticketing systems... which ones?
Q. Extensible:
  - has API to build customizable plugins
Q. Provisioning / Activation / Configuration management?
  - Starts / stops / restarts

----

http://www.shrubbery.net/rancid/

OpenNMS

Helpdesk: RT / OTRS (popular in europe) / Jira (* really good)

---------------------

InfoVista - Peformance and Reporting

---------

chrome w/ proxy

$ google-chrome --proxy-auto-detect

---------

$ curl 'http://www.google.com/finance/getprices?q=GOOG&x=NASD&i=120&p=1m&f=d,c,v,o,h,l' 2>&1 | tail -n 1 | cut -f2 -d','


-----------------------

Athena OSS Solutions

Telcordia... engineering-focused... concrete product.

Design Assistant - Automated design based on business rules.

-------------------

Renaming TV Shows

Get the perl script from here:
http://www.robmeerman.co.uk/coding/file_renamer

Then:

$ ~/temp/tvrenamer.pl --series="The Office" --season=6 --scheme=YY \
  --exclude_series --chdir=Office/

You can preprocess file names. E.g., below, tvrenamer does not recognize files
named 201.avi, 202.avi, etc., because it searchs for episode 201, 202, when
it should be searching for ep 01, 02 (for season 2). The following preproc
removes the first "2".

$ ~/temp/tvrenamer.pl --series="The Mighty Boosh" --season=2 --scheme=YY\
  --exclude_series --preproc='s/\d(\d\d)/$1/'

----------------

GnuPG

$ sudo port install gnupg

$ gpg --gen-keys
$ gpg --list-keys

--------------------

Amazon S3 / perl

$ sudo port install p5-amazon-s3

--------------

CVS Checkout

$ cvs -d anoncvs@openbsd.mirror.frontiernet.net:/cvs co src/sys/kern

SVN Checkout

$ svn checkout http://svn.freebsd.org/base/head/sys

$ svn checkout http://svn.freebsd.org/base/head/sys

-------------------

Generating source code posters for wickedmeanposters.com:

$ ./posterize.rb -s ~/tmp/emacs-icon.png -o ~/tmp/emacs.pdf -t ~/tmp/emacs.txt -p 24 -w 36 -h 36 -v --code

- Load pdf in Preview.
- Save as TIFF, LZW compressed, 300DPI
- Create two screenshots:
  + full poster: emacs-shot.png
  + zoomed in: emacs-zoom1.png
- Log onto imagekind.com and upload
  + tags: linux bsd software code emacs
  + Subject: Text/Words
  + Genre: Generative Art
  + Medium: Digital
  + Medium Sub-Category: Vector
  + Decor: Modern

---------------------------------------------------
---------------------------------------------------

Setting up a new mac:

Prefs:
  Dock
  Finder (icon size)
  Caps -> Ctrl
  Expose
  Hot corners
  Terminal / MacVim fonts, colors
  Filevault

Enable:
  SSH

Chrome Beta
XCode
MacPorts (Fink may be better now, since its binary)
MacVim
Inconsolata Font
Evil Tomato: w p x c
Transmission
iStat Menus
Flux
Band-in-a-Box
Reaper64
Vidalia (Tor)
MacPorts packages:
  git scons ghc gnupg2 gpg-agent p5-amazon-s3
  python27

Install GPG keys:
  $ cd w/panic
  $ gpg2 --import public.txt
  $ gpg2 --import private.txt

Restoring backups:
-----------------

Install Brackup:

  $ sudo cpan
  cpan> o conf prerequisites_policy follow
  cpan> o conf commit
  cpan> force install Net::Amazon::S3
  cpan> force install Brackup

Download relevant targets:

  $ brackup-target amazon list_backups
  $ brackup-target amazon get_backup mac_anki-1277946024

    or

  $ brackup-target amazon get_backups

Initialize GPG:

  $ eval $(gpg-agent --daemon)
  $ sudo ln -s /opt/local/bin/gpg2 /opt/local/bin/gpg

Restore:

  (You will need your AWS keys and your private key password for this)

  $ brackup-restore -v --from=mac_anki-1277946024.brackup --to ~/tmp --all

----------------------

/opt/local/bin/rsync -X -A -a -H -x -S -v --partial --progress -z \
      --exclude-from EX.file --delete --delete-excluded $SRC $DST


=-----------------------

TrueCrypt Time Machine

  $ defaults write com.apple.systempreferences TMShowUnsupportedNetworkVolumes 1

(Otherwise TM will not recognize the volume)

-------------------------------

Updating Throttler Registry

$ cd work/throttler/google3
$ blaze build balancing/throttler/registry/internal/...
$ mpm  build balancing/throttler/registry
$ mpm packageinfo balancing/throttler/registry
$ mpm setlabel balancing/throttler/registry test 2

Push...

$ cd work/production/google3/production/borg/throttler
$ vi templates/throttler_template.borg
$ <set MPM version to test>
$ cd google3
$ borgcfg --borguser=throttler gg/throttler.borg update \
    throttler.throttler_registry

Set live


-----------------------

SkinnyDNS / skinnydns

TODO:

- SkinnyHelpers should be a namespace, not a cache
- SkinnyCache should be SkinnyResolver
- Should cache misses lead to chubby queries?

---------- Running Tests ---------------

$ blaze test --test_arg="--vmodule=multibns*=5" :multibns_zone_test

$ blaze test --nocache_test_results --test_arg="--vmodule=skinny*=5,multibns*=5" :multibns_zone_test

Flags for thread saftey analysis:

$ blaze test ... --copt=-Wthread-safety -k

------------ Debugging -------------
# Production ChubbyDNS query

$ dig 0.adsw.zombiereaper_admixer.ads-backend.oa.borg.google.com

# Build and startup server

$ blaze run chubby/dns:skinnydns -- --dns_port 9999 --zones=skinny:skinny.google.com:/ls/test/home/mmuthanna/skinny,mbns:mbns.google.com:/ls/test/home/mmuthanna/mbns --logtostderr --vmodule=skinny*=5,multibns*=5

# Create BNS entries

$ lockserv /ls/test/home/mmuthanna
$ lockserv mkdir /ls/test/home/mmuthanna
$ lockserv mkdir /ls/test/home/mmuthanna/skinny
$ lockserv mkbns /bns/test/home/mmuthanna/skinny/job1 10.10.10.10:1234 10.10.10.11:2345

# Test DNS resolution
$ dig @localhost -p 9999 job1.skinny.google.com

; <<>> DiG 9.7.0-P1 <<>> @localhost -p 9999 job1.skinny.google.com
; (2 servers found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 7355
;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0
;; WARNING: recursion requested but not available

;; QUESTION SECTION:
;job1.skinny.google.com.                IN      A

;; ANSWER SECTION:
job1.skinny.google.com. 180     IN      A       10.10.10.10
job1.skinny.google.com. 180     IN      A       10.10.10.11

;; Query time: 0 msec
;; SERVER: 127.0.0.1#9999(127.0.0.1)
;; WHEN: Tue Dec 20 12:31:39 2011
;; MSG SIZE  rcvd: 72

# Create ResolvedAddr entries

$ lockserv mkdir /ls/test/home/mmuthanna/skinny/dir
$ lockserv cp /ls/oa/ns/stout/10.76.19.144:8040-66300001  /ls/test/home/mmuthanna/skinny/dir/addr2
$ lockserv cp /ls/oa/ns/stout/10.76.101.200:8040-66100001 /ls/test/home/mmuthanna/skinny/dir/addr1

$ dig @localhost -p 9999 addr1.dir.skinny.google.com

# MBNS

$ lockserv cp test.mbns /ls/test/home/mmuthanna/mbns/test

----------------------
Nameserver:

$ dig @localhost -p 9999 -t ns ey.borg.google.com

; <<>> DiG 9.7.0-P1 <<>> @localhost -p 9999 -t ns ey.borg.google.com
; (2 servers found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 36795
;; flags: qr aa rd; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 0
;; WARNING: recursion requested but not available

;; QUESTION SECTION:
;ey.borg.google.com.    IN  NS

;; ANSWER SECTION:
ey.borg.google.com. 1800  IN  NS  chubby-ey-000a.prodz.google.com.
ey.borg.google.com. 1800  IN  NS  chubby-ey-000b.prodz.google.com.
ey.borg.google.com. 1800  IN  NS  chubby-ey-000c.prodz.google.com.
ey.borg.google.com. 1800  IN  NS  chubby-ey-000d.prodz.google.com.
ey.borg.google.com. 1800  IN  NS  chubby-ey-000e.prodz.google.com.

;; Query time: 0 msec
;; SERVER: 127.0.0.1#9999(127.0.0.1)
;; WHEN: Fri Aug 17 13:40:26 2012
;; MSG SIZE  rcvd: 187

---------------

Git5 / git5

$ git5 init
$ git checkout -b new_branch
$ git5 track chubby/dns
$ git add new_file.cc new_file.h

code code

$ git commit -a
$ git5 export
$ git5 mail -m person --cc team -b BUGID (Only run this once)

code fix code

$ git5 export

code fix code

$ git5 export -e (To change CL description, if necessary)

code fix code

$ git5 submit

Git5 TAP presubmit (alternative to tap_presubmit):

First test with thread saftey on:

$ blaze test --copt=-Wthread-safety -- //chubby/...

$ git5 export --tap_options=trueHead --submit-queue --tap-project=chubby_opt.staging

$ git5 export --tap_options=trueHead --submit-queue --tap-project=chubby.staging,chubby_opt.staging,chubby_piii.staging

Also use: components,components.opt,components.piii

To rerun broken tests (get OCL number from previous test)

$ git5 export --tap_options="trueHead,rerun=OCL:32157186:BASE:32234505:1343241699608:8fe8944c" --submit-queue --tap-project=chubby.staging,chubby_opt.staging,chubby_piii.stagin/

https://sites.google.com/a/google.com/chubby-dev/before-you-submit

----------------------------------------

$ dremel

$ define table Chubby /cns/gh-d/home/ferret/dremel/ferret.20120124/FerretFileData-*
$ select user, sum(size) from Chubby group by user

$ select user, sum(size) as s from Chubby group by user order by s desc;

$ select user, sum(size) as s from Chubby where (left(name, 4) = "/ls/") group by user order by s desc;

+-------------------------------------------------+------------+
| user                                            | s          |
+-------------------------------------------------+------------+
| bt-sre                                          | 1725671353 |
| chubby-co                                       | 1394420125 |
| public-borgmaster                               |  225255730 |
| fallback                                        |  215372503 |
| quotaserver                                     |  187129807 |
| *                                               |  166675254 |
| sstable                                         |  119875859 |
| social-frontend                                 |  109603536 |
| colossus                                        |   97798666 |
| blobstore-team                                  |   94834118 |
| pinax-devel                                     |   75803311 |
| megastore                                       |   67806849 |
| bigtable-test                                   |   67617942 |
| abuse-team                                      |   59020517 |
| gws-team                                        |   57555457 |

dremel> select user, sum(replicated_size)/5 as s from Chubby where (left(name, 4) = "/ls/") group by user
 order by s desc;
+-------------------------------------------------+--------------+
| user                                            | s            |
+-------------------------------------------------+--------------+
| megastore                                       | 9446754788.2 |
| bt-sre                                          | 3070787184.0 |
| chubby-co                                       | 2998171850.0 |
| ip:localhost                                    | 2825469095.2 |
| onegoogle-push                                  | 2819675269.8 |
| trafficmanager-prod                             |  846492198.6 |
| uft                                             |  729300625.2 |
| *                                               |  727882175.8 |
| public-borgmaster                               |  657887068.0 |
| zipit-prod                                      |  534086948.6 |
| fallback                                        |  516869934.0 |
| midas                                           |  416783133.4 |
| gws-team                                        |  416697611.2 |
| sierra-prod                                     |  411139704.6 |
| ads-database                                    |  409165385.4 |
| blobstore-team                                  |  393859592.2 |
| kansas-tech                                     |  317811497.4 |
| loas                                            |  248354848.2 |


------------------------------

PMDC / pmdc / power domain shell

/ome/build/static/projects/powergrab/power_domain_shell

List domains for specific machine.
powerdomains> m wba1          (wba1 = WB first machine)
Domain: 58/A-2-B-1-9
Domain: 58/A-2-B-1
Domain: 58/A-2-B

List machines in domain.
powerdomains> dm 58/A-2-B-1-9         (58 is MDB building ID for WB)
Machines (76): wba1 wba2 wba3 wba4 wba5 wba6 wba7 wba8 wba9 wba10 wba11 wba12 wba13 wba14 wba15 wba16 wba17 wba18 wba19 wba20 wba21 wba22 wba23 wba24 wba25 wba26 wba27 wba28 wba29 wba30 wba31 wba32 wba33 wba34 wba35 wba36 wba37 wba38 wbb1 wbb2 wbb3 wbb4 wbb5 wbb6 wbb7 wbb8 wbb9 wbb10 wbb11 wbb12 wbb13 wbb14 wbb15 wbb16 wbb17 wbb18 wbb19 wbb20 wbb21 wbb22 wbb23 wbb24 wbb25 wbb26 wbb27 wbb28 wbb29 wbb30 wbb31 wbb32 wbb33 wbb34 wbb35 wbb36 wbb37 wbb38

------------------

Stout release branch:

Use perforce. Can't use git5.

Add line:

//depot/branches/stout_release_branch/... //mmuthanna-chubby-release-branch-3/...

$ g4 sync

(Lots will sync, but branches are thin.)

Go into specific branch and build.

$ blaze build -c opt --copts

$ gdb blaze-bin/chubby/stout/internal/lockserver_proxy ~/tmp/core.eeax47

$ bt

(gdb) frame 14
#14 0x00000000006e3e64 in LockServiceImpl::OpenAndGetStat (this=0x61cdf00, name="./state", options=...,
    handle=0x3e17128, in_info=<optimized out>, op=<optimized out>)
    at chubby/lib/internal/lockserviceimpl.cc:1235
1235                                       in_info, op);
(gdb) frame 12
#12 0x0000000000704aa4 in LockServiceMulti::OpenAndGetStatMountPoint (name=<optimized out>,
    options=<optimized out>, handle=<optimized out>, info=<optimized out>, op=<optimized out>,
    returned_early_not_mountpoint=0x2b0a08bc3eff) at chubby/lib/internal/lockservicemulti.cc:505
505         CHECK(*returned_early_not_mountpoint);
(gdb) p name
$1 = <optimized out>
(gdb) frame 14
#14 0x00000000006e3e64 in LockServiceImpl::OpenAndGetStat (this=0x61cdf00, name="./state", options=...,
    handle=0x3e17128, in_info=<optimized out>, op=<optimized out>)
    at chubby/lib/internal/lockserviceimpl.cc:1235
1235                                       in_info, op);
(gdb) frame 16
#16 0x0000000000415aa0 in LockServerWireProxy::Open (this=0x2023000, rpc=<optimized out>,
    arg=0x5667860, result=<optimized out>, callback=<optimized out>)
    at chubby/stout/internal/lockserver_proxy.cc:2021
2021    RPC_HANDLER2(Open,                Open);         // ProcessOpen
(gdb) p arg
$2 = (const LockServerWire_Open_Arg *) 0x5667860
(gdb) p (LockServerWire_Open_Arg) *(0x5667860)
$3 =
    <session:<auth:"ybi" session_id:8516979337 session_check:2359941371023575317 epoch:8531214337 call_id:74> name:"./state" handle_info:<open_mode:3 handle:8516979608 name:"/config/cdd/ee/rpcacl_ybi_ybi-demodays2.pods_server" instance:8524414512 handle_check:7501053341092638300 notification_mask:0> mode:2 type:0 notification_mask:0 sequencer:"" lock_delay_ms:0>


------------------------

codex / printproto (BNSAddrs / BNSMeta)

$ printproto --raw_protocol_buffer --message BNSAddrs boo

----------------------------------------

tail -10000 email_to_phone.log | grep 'X-Original-From = ' | ruby -pe 'gsub(/.*From\s=\s/,"")' | sort | uniq

------------------------

Find telebot stragglers:
-----------------------

# tail -1000 email_to_phone.log | egrep '(X-Original-From|Subject)' | grep header | ./parse_log.rb

where parse_log.rb = below snippet

-------------------
#!/usr/bin/ruby -n

require "pp"; 

BEGIN { $messages = {}; }

if ($_ =~ /\[(.+-.+-.+)T.*\].*From = (.*)$/) then
        time=$1; address=$2;
        address.chomp!;
end;

if !$messages.has_key?(address) then $messages[address]=[]; end; 

if ($_ =~ /\[(.*)\].*Subject = (.*)$/) then
        $messages[address].push("#{time}: #{$2}");
end; 

END { $messages.each { |k, v| puts k; v.each { |vv| puts "  #{vv}" }} }
----------------------------------


Checklist:

xargs -r # ignore empty
$ echo ${a%%.html}.htm

Ruby:

 1.upto(20).each { |x| puts x }

4.times { puts "blah" }

puts "x" * 10

print vs puts

puts "%s %s" % ["boo", "blah"]

$/ -- record separator (chomp removes it)

ARGF.each { |line| do_blah line }

STDIN.gets

first_arg, second_arg = ARGV

ARGV.first == ARGV[0]

txt = File.open(filename)
puts txt.read()

txt.each_line do |line|
  blah line
end

ls | ruby -ne 'if /(g)e(n)/ then puts `echo #{$1}` end'

(1..1000).inject { |sum, n| sum + n }

or

(1..1000).inject(&:+)


words = ["scala", "akka", "play framework", "sbt", "typesafe"]
tweet = "This is an example tweet talking about scala and sbt."

words.any? { |word| tweet.include?(word) }


file_text = File.read("data.txt")
file_lines = File.readlines("data.txt")

[49, 58, 76, 82, 88, 90].select { |n| n > 60 } # returns one array
[49, 58, 76, 82, 88, 90].partition { |n| n > 60 } # returns array of partitions

0> (1..10).zip(10..20)
=> [[1, 10], [2, 11], [3, 12], [4, 13], [5, 14], [6, 15], [7, 16], [8, 17], [9, 18], [10, 19]]


myarray.methods

=> ["find", "[]=", "inspect", "tap", "flatten", "<<", "reject!", "&", "clone", "rindex", "take", "push", "object_id", "__send__", "public_methods", "reject", "transpose", "instance_variable_defined?", "minmax", "choice", "freeze", "equal?", "member?", "each", "indexes", "delete", "*", "sort", "extend", "partition", "map!", "uniq", "+", "each_cons", "send", "any?", "each_with_index", "to_ary", "methods", "pack", "values_at", "-", "detect", "hash", "dup", "take_while", "join", "pop", "replace", "instance_variables", "to_enum", "reverse", "clear", "collect", "slice!", "permutation", "min_by", "indices", "|", "sort_by", "eql?", "size", "enum_cons", "group_by", "id", "instance_eval", "flatten!", "one?", "enum_with_index", "at", "singleton_methods", "delete_at", "find_index", "nitems", "taint", "empty?", "drop", "shift", "instance_variable_get", "enum_for", "map", "frozen?", "fill", "display", "instance_of?", "combination", "max_by", "uniq!", "method", "grep", "to_a", "first", "compact", "instance_exec", "type", "none?", "reverse_each", "fetch", "protected_methods", "find_all", "<=>", "delete_if", "==", "min", "reverse!", "insert", "===", "drop_while", "unshift", "instance_variable_set", "concat", "sort!", "assoc", "each_slice", "inject", "respond_to?", "kind_of?", "minmax_by", "product", "count", "to_s", "class", "last", "shuffle!", "index", "zip", "private_methods", "=~", "tainted?", "__id__", "select", "shuffle", "length", "max", "untaint", "nil?", "each_index", "entries", "cycle", "collect!", "rassoc", "slice", "enum_slice", "reduce", "include?", "is_a?", "compact!", "[]", "all?"]


hping3
tcpdump


ruby: threads, time, sockets
ruby: bytes / bits / pack
man ip
man tcpdump


----
Time.now.methods
Time.methods
Time.now.to_i
Time.at(1331232648)
Time.now.hour/min/sec/usec
Time.now.asctime

----

Sockets

require 'socket'

s = TCPSocket.open(host, port)
data = socket.read

server = TCPServer.open(2000)

Thread.start(server.accept) do |client|
  line = client.gets
  client.puts(line)
  client.close
end


-------------------------


Beta
- Supercluster is a borg cell tb-sc, colossus has it's own cell tb-sc-d
- Separate chubby, flex and autopilot instances
- Power domains are simulated PMDCs via logical grouping of PDUs

PVT
- Supercluster is a borg cell cluster spanning 5 PMDCs - most likely vf-sc and colossus vf-sc-d (rather than vg*)
- Separate chubby, flex and autopilot instances
- VF cluster becomes non draining, VF non supercluster users opt into drains
- When PVT is complete convert PVT vf-sc borg and vf-sc-d cells to production SLO , no other changes required

Other production cells
Option 1
- Follow the PVT model, create a new borg and colossus cells following same naming scheme 
- We can create the borg cell (possibly colossus) in advance and populated SC users who run at regular SLO
- When PVT is concluded, switch the borg and colossus cells to SC SLO (colossus encoding setup / transition method TBD)
- Future growth of the supercluster requires users to change cells (for local users) and migration of cores from the public cell to SC cell over time
- If / when we deploy a jupiter spine in the cluster and elect to convert the entire cluster to a SC SLO we migrate existing users to the *-sc cell during a PCR.  This avoids impacting the existing supercluster users but does involve work for the users moving to the SC SLO.  There is some precedent to this naming convention from the colossus migration where GFS cells became colossus cells with the -d suffix

Option 2 (have discussed with pdahl but needs more vetting)
- Opt in users to the supercluster SLO via a whitelist, uses existing borg cell  (similar to flex model)
- Future growth accomplished by opting in more users


----

Resolve IP-range Issue

Software infrastructure expects a 1:1 mapping between IP block and cluster and this will not be true in a super cluster
Network infrastructure cannot support multiple IP ranges within a single Saturn fabric.
Software that needs to change (contact / SC owner)
//google/config/net.config and consumers.
Chipmunk (fenix@ / ??)
What: (used by cluster turnup, netconfig populated from chipmunk data. Chipmunk is part of nettools-team
FIXED: Announced on chipmunk-announce.
https://groups.google.com/a/google.com/forum/?fromgroups#!topic/chipmunk-announce/aSZh4TvHJB4
BWEnforcer (csg@ / mmuthanna@)
What: Requires BWE change (hostshaper) and a borglet/containerd rollout to the whole fleet.
There may be kernel changes involved too, which will require a kernel rollout to the whole fleet.
Status: BWE team is working on a document with 5 proposed solutions and are beginning to implement one as a test.
Network tools (//production/network)
Hydrofoils (josebiro@ / mmuthanna@)
What: Replacemenet for CLIBs sing Pluto switches that forward traffic to WCC clusters, the first deployment is in VE (South Carolina)
Status: Not an issue connectivity is to IP address, will just treat a supercluster as any other
GSLB (jtr@ / mmuthanna@)
What: Need to get rid of IP field is required for cluster turnups, tracking bug b/5823883 - requires gslb-dev work
Status: Need bug owner and timeline for changes
Network doctor (ND) (nethealth-team / mmuthanna@)
What: need to change the nettrack tables is the net_host_machines tables to populate the correct machine names. Network doctor (ND) relies on those tables to tell us about rack switch to machine links and populates SHDB with the machine name that it gets from the net_host_machines table. 
Status: NetHealth team reading through SC design
Mastermind
Dashboards may need to be updated depending on BWEnforcer solution.
Network chargeback is performed based on Mastermind data.
Various other parts of google3 (audit needed.)

-----------------

SkinnyMirror

Spurious notifications
Multiple updates to the same file
Multi threaded writes without losing sequential consistency
Rate control
Priorities
Manual mirror UI


----------------------

Chubby IC: (chubbymirror) mirror / Mirror: http://shortn/_HQ6Cerz15y

rate({job="chubbymirror",var="lockservice-ops"}[5m])[30m]

------------------------

$ git log --graph --pretty=oneline --abbrev-commit --color --decorate

------------------

BNS Aggregator
Fri Apr  6 16:30:28 EDT 2012

$ lockserv stat /ls/fa/ns/aggregator/logs-sec/syslog

$ lockserv stat /ls/fa/borg/fa/bns/logs-sec/syslog-on-borg.cell-fa.syslog

/ldap


-----------------

$ ./sum2 | md5sum | ruby -ne 'a = $_.chomp.split.first; print a[0..15].to_i(16) ^ a[16..31].to_i(16)'
------------

Update ea and qa generic balancers.

--------------

EC2 / ec2 / aws / Amazon

Generate X.509 certs first.

Check running instances:

$ ec2-describe-instances

Import my own ssh keypair:

$ ec2-import-keypair --region us-east-1 --public-key-file .ssh/id_rsa.pub mohit

Get AMI image: http://www.ubuntu.com/cloud/public/deploy
Or use Ubuntu AMI locator: http://cloud.ubuntu.com/ami/

Maverik 64-bit image from us-east-1: ami-cef405a7

Create a security group:

$ ec2-add-group web -d 'All public facing web (port 80 and 443) instances'
$ ec2-authorize web -P tcp -p 22 -s 0.0.0.0/0
$ ec2-authorize web -P tcp -p 80 -s 0.0.0.0/0
$ ec2-authorize web -P tcp -p 443 -s 0.0.0.0/0
$ ec2-authorize web -P default -t icmp -1:-1

Start the instance:

$ ec2-run-instances ami-cef405a7 --instance-count 1 --instance-type m1.large --key mohit --group dev

$ ec2-terminate-instance (instance number)

(The above is super expensive. Try t1.micro.)

Instance types: http://aws.amazon.com/ec2/instance-types/

$ ec2-run-instances ami-cef405a7 --instance-count 1 --instance-type t1.micro --key mohit --group dev
RESERVATION     r-b61ab5db      645679559401    dev
INSTANCE        i-cf1f42a3      ami-cef405a7                    pending mohit   0 t1.micro 2011-02-21T14:22:20+0000        us-east-1a      aki-427d952b              monitoring-disabled                                      ebs                       paravirtual      xen


To connect to instance:

$ ec2-describe-instances

(Find public IP)

$ ssh -i key.pem ubuntu@ec2-50-17-12-159.compute-1.amazonaws.com

(first time on machine)

$ sudo tasksel --section server

Install stuff:
  - mysql client
  - scala
  - sqlalchemy

-----------------------

Associate IP address to ec2 instance:

$ ec2-associate-address 184.73.201.187 -i i-8eda73e4

---------------

Attach an arbitrary volume:

$ ec2-attach-volume vol-78f78410 -i i-cf1f42a3 -d /dev/sdf

on the machine:
$ sudo mkfs.ext4 /dev/sdf
$ sudo mkdir /mnt/vol1
$ sudo mount /dev/sdf /mnt/vol1

-------------

Create image:

Put initialization stuff in /etc/rc.local.

It's good practice to stop instances before creating an image, for consistency's
sake.

But, you don't have to (use --no-reboot to ec2-create-image).

$ ec2-stop-instances i-cf1f42a3

Detach non-root volumes, if necessary. If you don't EC2 will create an image
of the attached volumes too, and recreate them upon new instances.

$ ec2-detach-volume vol-78f78410

$ ec2-create-image i-cf1f42a3 -n dev-server-20110221 -d "Ubuntu 10.10 64-bit dev server with python and scala installed."
IMAGE	ami-a237c4cb

Restart instance:

$ ec2-start-instances i-cf1f42a3
$ ec2-associate-address 184.73.201.187 -i i-cf1f42a3

----------------

test app: autotester00 / jamestester

--------------------

Bitmap to Vector

$ autotrace --output-format pdf me.png --output-file me30.pdf -report-progress --despeckle-level 10  --despeckle-tightness 1.0

$ autotrace --output-format pdf me.png --output-file me.pdf -report-progress --despeckle-level 10 --despeckle-tightness 2.0 --color-count 2

$ autotrace --output-format pdf me.png --output-file me.pdf -report-progress --despeckle-level 10 --despeckle-tightness 2.0 --color-count 50


----------------------

Andale / andale

$ /home/build/static/projects/gaia/tools/cfg2resources.par --users=bladeservice-prod --borg_reserve_ratio 0:0:0 google3/production/borg/bladeservice/??/prod.borg

---------------------


Capistrano / capistrano

Need to hack /etc/ssh_config. Also need custom ~/.ssh/config

Host *.muthanna.com
  User mohit
  PasswordAuthentication no
  ForwardAgent yes
  IdentityFile ~/.ssh/id_rsa
  IdentityFile ~/.ssh/id_dsa
  Ciphers 3des-cbc
  Port 22

------------------------------

Running fabric:

Need -a or it calls up ssh_agent, and asks for passphrase.

$ cat fabfile.py

from fabric.api import run

def host_type():
  run('uname -a')

$ /opt/local/Library/Frameworks/Python.framework/Versions/2.7/bin/fab -a -H mohit@evil.muthanna.com host_type


--------------------

default ssh escape key: ~
(only valid on new line)

To quit connection: <Enter> ~ .

--------------------

Interview:

- sysadmin / networks
- languages / static/dynamic
- OS
- databases
- web
- source control
- code reviews
- testing
- monitoring
- clouds
- production

---------------------

GSLB Bigtable users

grads-server-test abuse.mr
abuseiam
idverification
activites backend (Google Plus)
omnibox
social-notifications-backend
rtb-api, rtb-snippets (realtime bidding)
ad-exchange
ads-affiliate-network
ads-review
ads-beaker
ads-columbo
ads-crawl
ads-dartsearch
ads-doubleclick-copy-status
ads-export-tools
ads-frontend
ads-g2d2-budget
ads-g2d2-billing
ads-geyser
ads-gmob
ads-keywords
ads-landingpages
billing-payments

---------------------------

Supercluster failure tests:

$ ~kaneda/failure_domain_tool --cell=tb-sc --chubby_path_format="/ls/%s/home/kaneda/test" --fileset_version_suffix=-new

$ echo 42/A-2-H-1,tbej1,tbej10,tbej11,tbej12,tbej13,tbej14,tbej15,tbej16,tbej17,tbej2,tbej3,tbej4,tbej5,tbej6,tbej7,tbej8,tbej9,tbet1,tbet10,tbet11,tbet12,tbet13,tbet14,tbet15,tbet16,tbet17,tbet2,tbet3,tbet4,tbet5,tbet6,tbet7,tbet8,tbet9,tbew1,tbew2,tbew3,tbfc1,tbfc2,tbfc3,tbff1,tbff2,tbff3 | ruby -ne 'puts $_.split(",").join(" ")'
$ stubby call blade:maya-calendar Maya.ScheduleDisruption --infile ~/work/scripts/disrupt.txt

Check for errors here:
http://google3/?fileprint=//depot/google3/production/maya/public/maya.proto

Maya dashboard:
http://0.calendar.calendar_server.maya-prod.we-sc.borg.google.com:25429/cluster-tb

Errors:

  DEDICATED = 1;  // Scope contains a dedicated machine.
  UNDRAINABLE_MACHINE = 2;  // Scope contains a machine which is undrainable.
  UNSCHEDULABLE = 3;  // No room in schedule for scope.
  UNKNOWN_SCOPE = 4;  // Cannot find this scope.
  UNKNOWN = 5;
  NO_MACHINES = 6;  // Scope contains no machines.
  INSUFFICIENT_CAPACITY = 7; // Not enough free capacity in cluster for drain.

$ stubby call blade:maya-calendar Maya.GetDisruptionUpdate '
> cluster: "we"
> disruption_id: 2401'

disruption_id: 2401
data_id: 0x9331aefed4511db1
disruption_status <
  in_progress <
    scope_set <
      scope <
        scope_type: 2
        scope_name: "wecu1switch"
      >
    >
    estimated_drained: 1340140096
    drain_id: 2402
  >
>

$ stubby call blade:maya-calendar Maya.GetDisruptionUpdate '
cluster: "we"
disruption_id: 2401
> data_id: 0x9331aefed4511db1'

(Above will block for 5m or state change)


Wait for disruption status to say "drained". Then firewall away machines.


-----------------

6674483 - S3? Maintenance management system.

6404163 - Evaluate go/faildom (hal)
6468252 - Hal to follow up with azana, re: PCMS flow (hal)
3431306 - Contracts / figure out / roth (hal)
6230162 - Lifeforce - productiona (mo)
++++ jmillikin says it will be ready by next quarter.

Chubby - Design doc - close, open new one with chubby deployment / provisioning. (mo)
- Chubby DTF - find bug and open. (mo)

++++ DTF will not affect PVT or Offering 1, they have backup plans.


---
Meet with mbrody and jaj and jtr and hburch re: Autoreplacer Aristotle plans for PVT. (mo / hal)
---

Cooling from feldy.
borgmaster from kenji.
Talk to Eric about storage. (mo)

----

Updates

http://b/issue?id=1144858

SC Deployment Configuration Auditing

Goal: Ensure that superclusters are deployed with the correct configuration.

borg
borglets
chubby
svelte
chubblets
maya
d
colossus
flex.0

aristotle

--------------------------
$ gqui from /ls/wj/borg/wj-sc/users proto borg.BorgMasterUserMap

$ gqui from /tmp/users proto borg.BorgMasterUserMap | ruby -ne '$_.chomp!; if $_ =~ /\s+name:\s+"(\S+)"/ then name=$1; end; if $_ =~ /capability/ then if $_ =~ /MIGRATE/ then puts name; else name=""; end; end;'


-----------------------

GSLB Push / gslb

$ git5 init
$ git5 track google3/googledata/production/gslbpush

# To test changes.
$ git5 birdpush test

-------------------


for user in census; do echo $user; /home/build/static/projects/tetris/clients/capabilities.par -u $user -c yh --add MIGRATE_FAILOVER_CLASS; done

for user in evenflow evenflow-seneca evenflow-ubiq gfp-photon evenflow-prod evenflow-photon ads-sre-stats adspam-filter; do echo $user; /home/build/static/projects/tetris/clients/capabilities.par -u $user -c pb --add MIGRATE_FAILOVER_CLASS; done

------------
CitC (citc)

Create client:

$ g4d -f foobar
Client in: /google/src/cloud/mmuthanna/foobar/google3

In stead of "cd", you can change directory with:
$ g4d <TAB>
$ g4d foobar

Standard workflow:

$ g4 add
$ g4 edit
$ g4 lint
$ g4 mail
$ g4 submit

Also:
$ g4 sync/pending/nothave/change
$ g4 revert
$ g4 mail/submit/rollback

----------

blaze test --test_output=streamed --test_arg=--gunit_filter=TestCase.TestMethod //my/project:testrule

https://wiki.corp.google.com/twiki/bin/view/Main/BlazeTesting#Running_a_single_test


-------------------

golang / blaze / glaze

Create BUILD file:
$ glaze dir

$ g4d foobar
$ cd experimental/users/mmuthanna/caster

$ blaze run caster -- --port 3000

$ stubby call localhost:3000 Stream.Cast
Message: "haha"
^D


----------------

# Need to do this for go tests
$ blaze test svelte_test --test_arg=--alsologtostderr